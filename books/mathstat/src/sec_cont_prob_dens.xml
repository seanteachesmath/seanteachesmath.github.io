<?xml version="1.0" encoding="UTF-8" ?>
<section xml:id="section-special-densities">
<title>Special probability densities</title>

<introduction>

<p>...</p>

</introduction>

<subsection xml:id="sub-continuous-unif">
<title>Continuous uniform</title>
<p>...</p> 

<definition xml:id="def-cont-unif">
<title>continuous uniform distribution</title>
<statement>
<p>A continuous random variable <m>\displaystyle X</m> has a
<term>continuous uniform distribution</term> and is referred to as a
<term>continuous uniform random variable</term> if and only if its
probability density is given by  <me>u(x; \alpha, \beta) =
\begin{cases}\dfrac{1}{\beta - \alpha}, \amp \quad \text{ for }\alpha
\lt x \lt \beta\\0, \amp \quad \text{elsewhere}\end{cases}</me> where
<m>\alpha, \beta \gt 0</m>.
</p>
</statement>
</definition>

<figure xml:id="fig-unif-plots">
	<caption>A folksy sketches of the continuous uniform
distribution.</caption>
		<image xml:id="image-unif-plots"
source="./images/unif.png"
width='50%'>
		</image>
</figure>

<theorem xml:id="thm-cont-unif-mean"> 
<title>mean and variance of continuous uniform</title>
<statement>
<p>The mean and variance of the uniform distribution are given by 
<me>\mu = \dfrac{\alpha + \beta}{2}\text{ and }\sigma^2 =
\dfrac{1}{12}(\beta-\alpha)^2</me>
</p>
</statement></theorem>


<exercise xml:id="chall-cont-unif-mgf">
<title>continuous uniform moment-generating function</title>
<statement>
<p> Find the moment generating function of the continuous uniform
distribution.
</p>
</statement>
</exercise>


<exercises>
 <exercise>
 <title>Problem 6.1</title>
 <statement>
<p>Show that if a random vriable has a uniform density with parameters
<m>\alpha</m> and <m>\beta</m>, the probability that it will take on a
value less than <m>\alpha + p(\beta - \alpha)</m> is <m>p</m>.
 </p>
 </statement>
 </exercise>
 
 <exercise>
 <title>Problem 6.3</title>
 <statement>
<p>If a random vriable has a uniform density with parameters
<m>\alpha</m> and <m>\beta</m>, find its distribution function.
 </p>
 </statement>
 </exercise>
 
</exercises>


</subsection>


<!--*****************************************-->
<!--*****************************************-->

<subsection xml:id="sub-exponential">
<title> Exponential family</title>
<introduction>
<p>Two distributions, the exponential and chi-square, are special cases
(i.e., parameterizations) of a very flexible distribution called the
gamma.</p> 
</introduction>
<!--*****************************************-->
<p>We are at this point fairly familiar with the calculation of
factorials. Factorials underlie our methods of counting, from
permutations to combinations and partitions. For example, <m>5! =
5\cdot4\cdot3\cdot2\cdot1 = 120</m>. What would it mean to ask for
<m>0.5!</m>?
</p>

<p>The gamma function allows us to generalize our concept of the
factorial to noninteger, and even many nonpositive, values.
</p>

 <definition xml:id="def-gamma-func">
<title>gamma function</title>
<statement>
<p>The <term>gamma function</term> is given by  <me>\Gamma(\alpha)
=\int_0^\infty y^{\alpha - 1}e^{-y}\,dy</me> where <m>\alpha \gt
0</m>.
</p>
</statement>
</definition>

<figure xml:id="fig-gamma">
	<caption>Graphs of the gamma function with a few key
values.</caption>
		<image xml:id="image-gamma"
source="./images/gammaplot.png"
width='50%'>
		</image>
</figure>

<!--><table xml:id="tab-gamma-vals">-->

<table xml:id="tab-gammas">
<title>A table of common gamma function values.</title>
<!--><sidebyside widths="50% 50%" haligns = "right left" valigns="middle
middle"> -->
<tabular>
<row bottom="medium"><cell><m>\alpha</m></cell>
<cell><m>\Gamma(\alpha)</m></cell> <cell>         
</cell><cell><m>\alpha</m> (cont.)</cell> <cell><m>\Gamma(\alpha)</m>
(cont.)</cell> </row>
<row><cell><m>\sfrac{1}{2}</m></cell> <cell><m>\sqrt{\pi}</m></cell> 
<cell>          </cell><cell><m>\sfrac{5}{2}</m></cell>
<cell><m>\sfrac{3\sqrt{\pi}}{4}</m></cell> </row>
<row><cell><m>1</m></cell> <cell><m>0! = 1</m></cell> <cell>         
</cell> <cell><m>3</m></cell> <cell><m>2! = 2</m></cell></row>
<row><cell><m>\sfrac{3}{2}</m></cell>
<cell><m>\sfrac{\sqrt{\pi}}{2}</m></cell> <cell>         
</cell><cell><m>\sfrac{7}{2}</m></cell>
<cell><m>\sfrac{15\sqrt{\pi}}{8}</m></cell></row>
<row><cell><m>2</m></cell> <cell><m>1! = 1</m></cell>  <cell>         
</cell><cell><m>4</m></cell> <cell><m>3! = 6</m></cell></row>
</tabular>
<!--><tabular>
<row bottom="medium"><cell><m>\alpha</m> (cont.)</cell>
<cell><m>\Gamma(\alpha)</m> (cont.)</cell> </row>
	<row><cell><m>\sfrac{5}{2}</m></cell>
<cell><m>\sfrac{3\sqrt{\pi}}{4}</m></cell> </row>
	<row><cell><m>3</m></cell> <cell><m>2! = 2</m></cell> </row>
	<row><cell><m>\sfrac{7}{2}</m></cell>
<cell><m>\sfrac{15\sqrt{\pi}}{8}</m></cell> </row>
	<row><cell><m>4</m></cell> <cell><m>3! = 6</m></cell></row>
</tabular>-->
<!--></sidebyside>-->
</table>

<definition xml:id="def-cont-gamma">
<title>gamma distribution</title>
<statement>
<p>A continuous random variable <m>\displaystyle X</m> has a
<term>gamma distribution</term> and is referred to as a
<term>gamma random variable</term> if and only if its probability
density is given by  <me>f(x; \alpha, \beta) =
\begin{cases}\dfrac{1}{\beta^\alpha
\Gamma(\alpha)}x^{\alpha-1}e^{-\sfrac{x}{\beta}}, \amp \quad \text{
for }0 \lt x\\0, \amp \quad \text{elsewhere}\end{cases}</me> where
<m>\alpha, \beta \gt 0</m>.
</p>
</statement>
</definition>


<figure xml:id="fig-gamma-plots">
	<caption>A few folksy sketches of the gamma distribution.</caption>
		<image xml:id="image-gamma-plots"
source="./images/gammas.png"
width='50%'>
		</image>
</figure>


<!--*****************************************-->

<theorem xml:id="thm-cont-gamma-moments"> 
<title>moments about the origin of the gamma</title>
<statement>
<p>The <m>r^{\text{th}}</m> moment about the origin of the gamma
distribution is given by 
<me>\mu_r' = \dfrac{\beta^r\Gamma(\alpha+r)}{\Gamma(\alpha)}</me>
</p>
</statement></theorem>

<theorem xml:id="thm-cont-gamma-mean"> 
<title>mean and variance of gamma</title>
<statement>
<p>The mean and variance of the gamma distribution are given by 
<me>\mu = \alpha\beta\text{ and }\sigma^2 = \alpha\beta^2</me>
</p>
</statement></theorem>

<theorem xml:id="thm-cont-gamma-mgf"> 
<title>moment-generating function of the gamma</title>
<statement>
<p>The moment-generating function of the gamma distribution is given by 
<me>M_X(t) = (1-\beta t)^{-\alpha}</me>
</p>
</statement></theorem>

<figure xml:id="fig-pois-exp1">
	<caption>Derivation of the exponential distribution from a Poisson
process (Part 1).</caption>
		<image xml:id="image-pois-exp1"
source="./images/poisson_exp.png"
width='80%'>
		</image>
</figure>

<figure xml:id="fig-pois-exp2">
	<caption>Derivation of the exponential distribution from a Poisson
process (Part 2).</caption>
		<image xml:id="image-pois-exp2"
source="./images/poisson_exp2.png"
width='80%'>
		</image>
</figure>


 <definition xml:id="def-cont-exp">
<title>exponential distribution</title>
<statement>
<p>A continuous random variable <m>\displaystyle X</m> has an
<term>exponential distribution</term> and is referred to as an
<term>exponential random variable</term> if and only if its probability
density is given by  <me>f(x; \theta) =
\begin{cases}\dfrac{1}{\theta}e^{-\sfrac{x}{\theta}}, \amp \quad \text{
for } 0 \lt x\\0, \amp \quad \text{elsewhere}\end{cases}</me> where
<m>\theta \gt 0</m>.
</p>
</statement>
</definition>

<figure xml:id="fig-exp-plots">
	<caption>A few folksy sketches of the exponential
distribution.</caption>
		<image xml:id="image-exp-plots"
source="./images/exps.png"
width='50%'>
		</image>
</figure>


<corollary xml:id="cor-cont-exp-mean"> 
<title>mean and variance of exponential</title>
<statement>
<p>The mean and variance of the exponential distribution are given by 
<me>\mu = \theta \text{ and }\sigma^2 = \theta^2</me>
</p>
</statement></corollary>

<exercise xml:id="exer-exp-mean">
<statement>
<p>By using the appropriate mathematical expectation, verify that the
mean of the exponential distribution is as stated above.
</p>
</statement>
</exercise>

<remark xml:id="rmk-exp">
<statement>
<p>The function used in <xref ref="ex-exponential"/> and <xref
ref="ex-exponential"/> was an exponential distribution with
<m>\lambda = \sfrac{1}{\theta} = 3</m>.  Occasionally the exponential is
parameterized by <m>\lambda \gt 0</m> with 
<me>f(x; \lambda) =
\begin{cases}\lambda e^{-\lambda x}, \amp \quad \text{
for } 0 \lt x\\0, \amp \quad \text{elsewhere}\end{cases}</me>
</p>
</statement>
</remark>

<definition xml:id="def-cont-chi">
<title>chi-suqare distribution</title>
<statement>
<p>A continuous random variable <m>\displaystyle X</m> has a
<term>chi-square distribution</term> and is referred to as a
chi-square random variable if and only if its probability density is
given by  <me>f(x; \nu) =
\begin{cases}\dfrac{1}{2^{\sfrac{\nu}{2}}
\Gamma(\sfrac{\nu}{2})}x^{\frac{\nu-2}{2}}e^{-\sfrac{x}{2}}, \amp \quad
\text{
for }0 \lt x\\0, \amp \quad \text{elsewhere}\end{cases}</me> where
<m>\nu</m> is a parameter describing the <em> number of degrees of
freedom</em>.
</p>
</statement>
</definition>

<exercises>
 <exercise>
 <title>Problem 6.10(a)</title>
 <statement>
<p> Find the probability that a random variable will exceed <m>1</m> if
it has a gamma distribution with <m>\alpha=2, \beta=3</m>.
 </p>
 </statement>
 </exercise>
 
  <exercise>
 <title>Problem 6.23</title>
 <statement>
<p> A random variable <m>X</m> has a <em>Weibull distribution</em> if
and only if its probability density is given by 
<me>f(x; \alpha, \beta) =
\begin{cases}kx^{\beta-1}e^{-\alpha x^\beta}, \amp \quad
\text{
for }0 \lt x\\0, \amp \quad \text{elsewhere}\end{cases}</me> for
<m>\alpha, \beta \gt 0</m>.  Express <m>k</m> in terms of <m>\alpha,
\beta</m>.
 </p>
 </statement>
 </exercise>

 
 <p> See also: WeBWorK.</p>
</exercises>

</subsection>




<!-- *********************************** -->
<subsection xml:id="sub-beta">
<title>Beta distribution</title>
<introduction>
<p>In some applications, the beta distribution (which is a probability
density itself) is actually used to described the distributions of
<em>other</em> probabilities.</p></introduction>

<definition xml:id="def-cont-beta">
<title>Beta distribution</title>
<statement>
<p>A continuous random variable <m>\displaystyle X</m> has a
<term>Beta distribution</term> and is referred to as a
Beta random variable if and only if its probability density is given by 
<me>f(x; \alpha, \beta) =
\begin{cases}\dfrac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^
{\alpha-1}(1-x)^{\beta-1}, \amp \quad \text{
for }0 \lt x \lt 1\\0, \amp \quad \text{elsewhere}\end{cases}</me> where
<m>\alpha, \beta \gt 0</m>.
</p>
</statement>
</definition>

<figure xml:id="fig-beta-plots">
	<caption>A few folksy sketches of the beta distribution. Notice that
for 
<m>\alpha = \beta = 0.5</m>, the PDF has vertical asymptotes at <m>x =
0, 1</m>. 
For <m>\alpha = \beta = 2</m>, the PDF simplifies to <m>f(x; 2, 2) =
6x(1-x)</m>.</caption>
		<image xml:id="image-beta-plots"
source="./images/betas.png"
width='50%'>
		</image>
</figure>

<remark xml:id="rmk-beta">
<statement>
<p>The function used in <xref ref="ex-poly"/> was a beta distribution
with <m>\alpha=\beta=5</m>.
</p>
</statement>
</remark>

<exercises>
 <exercise>
 <title>Problem 6.25(a)</title>
 <statement>
<p> Verify that the integral of the beta density function from
<m>-\infty</m> to <m>\infty</m> equals <m>1</m> if it has a gamma
distribution with <m>\alpha=2, \beta=4</m>.
 </p>
 </statement>
 </exercise>
 
 <p> See also: WeBWorK.</p>
</exercises>


</subsection>

<!-- **************************************************** -->

<subsection xml:id="sub-normal">
<title>Normal distribution</title>
<p>...</p> 

<definition xml:id="def-cont-normal">
<title>Normal distribution</title>
<statement>
<p>A continuous random variable <m>\displaystyle X</m> has a
<term>normal distribution</term> and is referred to as a
normal random variable if and only if its probability density is given
by  <me>n(x; \mu, \sigma) = \dfrac{1}{\sigma\sqrt{2\pi}}
e^{-\dfrac{1}{2}\left(\dfrac{x-\mu}{\sigma}\right)^2}, \quad \text{
for }-\infty \lt x \lt \infty</me> where <m>\sigma \gt 0</m>.
</p>
</statement>
</definition>

<theorem xml:id="thm-cont-normal-mean"> 
<title>mean and variance of normal</title>
<statement>
<p>The mean and variance of the normal distribution are given by 
<me>\mu = \mu\text{ and }\sigma^2 = \sigma^2</me>
</p>
</statement></theorem>

<theorem xml:id="thm-cont-normal-mgf"> 
<title>moment-generating function of the normal</title>
<statement>
<p>The moment-generating function of the normal distribution is given by

<me>M_X(t) = e^{\mu t + \sfrac{1}{2}\sigma^2t^2}</me>
</p>
</statement></theorem>

<remark xml:id="rmk-params-normal">
<statement>
<p>
The PDF is parameterized by <m>\mu</m> and <m>\sigma = \sqrt{\sigma^2} =
\sqrt{\operatorname{Var}(X)}</m>.
</p>
</statement>
</remark>

<corollary xml:id="corr-std-normal">
<statement>
<p>
The <term>standard normal</term> has <m>\mu = 0</m> and <m>\sigma =
1</m> and is given by <me>f(x; \mu = 0, \sigma = 1) =
\dfrac{1}{\sqrt{2\pi}}
e^{-\dfrac{1}{2}x^2}, \quad \text{
for }-\infty \lt x \lt \infty</me>
</p>
</statement>
</corollary>

<remark xml:id="rmk-table-std-normal">
<statement>
<p>
It is the standard normal distribution for which areas under the curve
given by <me>\int_0^z \dfrac{1}{\sqrt{2\pi}}
e^{-\dfrac{1}{2}x^2}\,dx</me> are tabulated. </p>

<figure xml:id="fig-std-tab">
	<caption>Table of standard normal probabilities. The highlighted
entry "<m>0.2224</m>" corresponds to the probability <m>P(z \lt 0.59) =
0.2224</m> and gives the area under the graph of the standard normal
curve between <m>z=0</m> and <m>z =0.59</m>.</caption>
		<image xml:id="image-std-tab"
source="./images/ztab.png"
width='80%'>
		</image>
</figure>

<p>Other areas can be calculated by symmetry. </p>
</statement>
</remark>


<theorem xml:id="thm-cont-std-normal"> 
<title>transforming to standard normal</title>
<statement>
<p>If <m>X</m> has a normal distribution with <m>\mu</m> and
<m>\sigma</m>, then <m>\displaystyle Z = \dfrac{X - \mu}{\sigma}</m> has
the standard normal distribution.
</p>
</statement></theorem>

<p>A few special probabilities for the standard normal are given by
<ol>
<li><p><m>P(-\infty \lt z \lt 0) = 0.5</m></p></li>
<li><p><m>P(0 \lt z \lt \infty) = 0.5</m></p></li>
<li><p><m>P(-\infty \lt z \lt \infty) = 1</m></p></li>
<li><p><m>P(-a \lt z \lt a) = 2\cdot P(0 \lt z \lt a)</m></p></li>
</ol>
</p>

<example xml:id="ex-std-norm-probs">
<title>probabilities from the standard normal</title>
<statement>
<p>
Find the following probabilities from the standard normal distribution.
<ol>
<li><p><m>P(|z|\lt 0.3)</m></p></li>
<li><p><m>P(0.3 \lt z \lt 0.6)</m></p></li>
<li><p><m>P(0.6 \lt z)</m></p></li>
</ol>
</p>

<solution>
<p>To find <m>P(|z|\lt 0.3)</m>, we must first find <m>P(0 \lt z \lt
0.3)</m>. Once we have that, we can double this value by symmetry of the
PDF. </p>
<figure xml:id="fig-std-norm1">
	<caption>Area under the curve corresponding to desired
probability.</caption>
		<image xml:id="image-std-norm1"
source="./images/std_norm1.png"
width='50%'>
		</image>
</figure>

<p>Now to find <m>P(|z|\lt 0.3)</m>, we have the following image. By
table we have that <m>P(0 \lt z \lt 0.3) = 0.1179</m>, so 
<m>P(|z|\lt 0.3) = 2(0.1179) = 0.2358</m>.  For simplicity we will use
an equality here, even though the tabulated areas are numerical
approximations.</p>
<figure xml:id="fig-std-norm2">
	<caption>Area under the curve corresponding to desired
probability.</caption>
		<image xml:id="image-std-norm2"
source="./images/std_norm2.png"
width='50%'>
		</image>
</figure>

<!--><li><p><m>P(0.3 \lt z \lt 0.6)</m></p></li>
<li><p><m>P(0.6 \lt z)</m></p></li>
</ol>-->
<p>Now to find <m>P(0.3 \lt z \lt 0.6)</m>, we have the following image.
 To solve this problem we find the area from <m>z=0</m> to <m>z=0.6</m>,
then subtract the area from <m>z=0</m> to <m>z=0.3</m>.</p>
<figure xml:id="fig-std-norm3">
	<caption>Area under the curve corresponding to desired
probability.</caption>
		<image xml:id="image-std-norm3"
source="./images/std_norm3.png"
width='50%'>
		</image>
</figure>
<p>Now to find <m>P(0.6 \lt z)</m>, we have the following image.  To
solve this problem we find the area from <m>z=0</m> to <m>z=0.6</m>,
then subtract this from the area under the entire right half of the
curve.  So <m>P(0.6 \lt z)</m> = 0.5 - 0.2257 = 0.2743</p>
<figure xml:id="fig-std-norm4">
	<caption>Area under the curve corresponding to desired
probability.</caption>
		<image xml:id="image-std-norm4"
source="./images/std_norm4.png"
width='50%'>
		</image>
</figure>

</solution>
</statement>
</example>

<example xml:id="ex-std-norm-probs2">
<title>probabilities from the standard normal</title>
<statement>
<p>
Find the associated standard normal random variable <m>Z</m> for a normal random variable
<m>X</m> with <m>\mu = 19.7</m> and <m>\sigma = 9.1</m> and use it to
calculate the probability that <m>Z \gt 25</m>.
</p>

<hint>
<p> Transform to <m>Z</m> then use the table.
</p>
</hint>
</statement>
</example>

<exercises>
 <exercise>
 <title>Problem 6.31</title>
 <statement>
<p> Show that the normal distribution has a relative maximum at <m> x =
\mu</m> and inflection points at <m> x = \mu \pm \sigma</m>.
 </p>
 </statement>
 </exercise>
 
 <p> See also: WeBWorK.</p>
</exercises>


</subsection>

<!-- ***************************************** -->

<subsection xml:id="sub-normal-approx">
<title>Normal approximation to the binomial distribution</title>
<introduction><p>
...
</p></introduction>
<theorem xml:id="thm-cont-normal-binom"> 
<title>normal approximation to the binomial</title>
<statement>
<p>If <m>X</m> has a binomial distribution with parameters <m>n</m> and
<m>\theta</m>, then the moment-generating function of <m>
\dfrac{X-n\theta}{\sqrt{n\theta(1-\theta)}}</m> approaches <m> M_X(t) =
\underbrace{e^{\sfrac{1}{2}t^2}}_{\text{std. normal}}</m> as
<m>n\to\infty</m>.
</p>
</statement></theorem>
<p>This is because of a <m>1:1</m> correspondence between
moment-generating functions and PMFs/PDFs and the (unstated) fact that
if <m>M_X(t) \to M_Y(t)</m>, then <m>\text{the distribution of }X
\to\text{ the distribution of }Y</m>.</p>

<p>The approximation is true as <m>n\to\infty</m> and can be used when
both <m>n\theta, n(1-\theta) \gt 5</m>.  This is theoretically important
and was of great historical importance, but is less practically
important </p>

<p>Since calculating densities reqires intervals, a <em>continuity
correction</em> represents the binomial integer <m>k</m> by the
<em>standard normal</em> interval <m>(k-\sfrac{1}{2},
k+\sfrac{1}{2})</m> for the purposes of integration.
</p>

<exercises>
 <exercise>
 <title>Problem 6.75(a, b)</title>
 <statement>
<p> Make the normal approximation to <m>b(1; 150, 0.05)</m>. Is the
approximation reasonable? How does it compare to a (rounded) true value of <m>b(1;
150, 0.05) = 0.0036</m>?
 </p>
 </statement>
 </exercise>
 
 <p> See also: WeBWorK.</p>
</exercises>


</subsection>

 </section>
