<?xml version="1.0" encoding="UTF-8" ?>

<!--********************************************************************
Copyright 2020 Sean M. Laverty

This file is part of MathBook XML.

MathBook XML is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 or version 3 of the
License (at your option).

MathBook XML is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with MathBook XML. If not, see <http://www.gnu.org/licenses/>.
*********************************************************************-->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->

<chapter xml:id="chap-discrete"
xmlns:xi="http://www.w3.org/2001/XInclude">
<title>Discrete Random Variables</title>
<author><xref ref="slaverty"/></author>

<introduction>
<p>...</p>

<p>...</p>

<!--> <p><xref ref="slaverty" /> helped improve this chapter.</p>-->

</introduction>

<section xml:id="section-probability-distributions">
<title>Probability distributions</title>

<introduction>
<p> Some words.</p>
</introduction>

<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-single-variable-disc">
<title>Random variables and probability distributions</title>

<introduction>
<p> See sections 3.1, 3.2. Recommended problems: (pg80)1,3,4ab,5,6,7a</p>
</introduction>

<definition xml:id="def-probability-distribution-3-2">
<title>probability distribution</title>
<statement>
<p>
If <m>\displaystyle X</m> is a discrete random variable, the function
given by <m>\displaystyle f(x) = P(X = x)</m> for each <m>\displaystyle
x</m> within the range of <m>\displaystyle X</m> is called the
<term>probability distribution</term>.
</p>
</statement></definition>


<theorem xml:id="thm-conditions-3-1">
<title>conditions for probability distribution</title>
<statement>
<p>A function can serve as the probability distribution for a discrete
random variable <m>\displaystyle X</m> if and only if its values,
<m>\displaystyle f(x)</m>, satisfy the conditions 
<ol>
<li><p> <m>\displaystyle f(x) \ge 0</m> for each value within its
domain;</p></li>
<li><p> <m>\displaystyle \sum_x f(x) = 1</m>, where the summation
extends over all the values within its domain</p></li>
</ol>

</p>
</statement></theorem>


<definition xml:id="def-distribution-function-3-3">
<title>distribution function</title>
<statement>
<p>
If <m>\displaystyle X</m> is a discrete random variable, the function
given by 
<!--<me> F(x) = P(X \le= x) = \sum_{t \le= x} f(t) \text{for} -\infty <
x < \infty</me>
--> where <m>\displaystyle f(t)</m> is the value of the probability
distribution of <m>\displaystyle X</m> at <m>\displaystyle t</m>, is
called the <term>distribution function</term>, or the <term>cumulative
distribution (function)</term>, of <m>\displaystyle X</m>. 
</p>
</statement></definition>

<!--><theorem xml:id="thm-3-1">
<title>conditions for probability distribution</title>
<statement>
<p>A function can serve as the probability distribution for a discrete
random variable <m>\displaystyle X</m> if and only if its values,
<m>\displaystyle f(x)</m>, satisfy the conditions
<ol>
<li><p> <m>\displaystyle f(x) \ge 0</m> for each value within its
domain;</p></li>
<li><p> <m>\displaystyle \sum_x f(x) = 1</m>, where the summation
extends over all the values within its domain</p></li>
</ol>
</p>
</statement></theorem>-->


<theorem xml:id="thm-3-2">
<title>properties of a distribution function</title>

<statement>
<p>
The values <m>\displaystyle F(x)</m> of the distribution function of a
discrete random variable <m>\displaystyle X</m> satisfy the conditions
<ol>
<li> <m>\displaystyle F(-\infty) = 0</m> and <m>\displaystyle F(\infty)
= 1</m> (more carefully stated as <m>\displaystyle
\lim_{x\to-\infty}F(x) = 0</m> and <m>\displaystyle \lim_{x\to\infty}
F(x) = 1</m>);</li>
<li> if <m>\displaystyle a \lt b</m>, then <m>\displaystyle F(a) \le
F(b)</m> for any real numbers <m>\displaystyle a</m> and
<m>\displaystyle b</m></li>
</ol>
</p>
</statement></theorem>

</subsection>

<!-- <p> See sections 3.1, 3.2. Recommended problems: (pg80)1,3,4ab,5,6,7a</p> -->
<exercises>
 <exercise>
 <title>Problem 3.1</title>
 <statement>
<p>For each of the following, determine whether the given values can serve as the values of a probability distribution of a random variable with the range <m>x = 1, 2, 3, \text{ and } 4</m>:
<ol><li><p><m>f(1) = 0.25,f(2) = 0.75,f(3) = 0.25,\text{ and }f(4) = 0.25</m></p></li>;
<li><p><m>f(1) = 0.15,f(2) = 0.27,f(3) = 0.29,\text{ and }f(4) = 0.29</m></p></li>;
<li><p><m>f(1) = \dfrac{1}{19},f(2) = \dfrac{10}{19},f(3) = \dfrac{2}{19},\text{ and }f(4) = \dfrac{5}{19}</m></p></li>.
</ol>
 </p>
 </statement>
 </exercise>

 <exercise>
 <title>Problem 3.3</title>
 <statement>
<p>Verify that <m>\displaystyle f(x) = \dfrac{2x}{k(k+1)}</m> for <m>x=1, 2,
3, \dots, k</m> can serve as the probability distribution of a random
variable with the given range. <em>Bonus:</em> Find or describe
<m>F(x)</m>.}
 </p>
 </statement>
 </exercise>
 
  <exercise>
 <title>Problem 3.4b</title>
 <statement>
<p>Determine <m>c</m> so that the function <m>\displaystyle f(x) =
c{5\choose x}</m> for <m>x = 0, 1, 2, 3, 4, 5</m> can serve as a
probability distribution of a random variable with the given range.
 </p>
 </statement>
 </exercise>
 
    <exercise>
 <title>Problem 3.5</title>
 <statement>
<p>For what values of <m>k</m> an <me>f(x) = (1-k)k^x</me> serve as the
values of the probability distribution of a random variable with
countably infinite range <m>x = 0, 1, 2, \dots</m>?
 </p>
 </statement>
 </exercise>
 
     <exercise>
 <title>Problem 3.7a</title>
 <statement>
<p>Show that there are no values of <m>c</m> such that <me>f(x) =
\dfrac{c}{x}</me> can serve as the
values of the probability distribution of a random variable with
countably infinite range <m>x = 0, 1, 2, \dots</m>
 </p>
 </statement>
 </exercise>
 
      <exercise>
 <title>Problem 3.6</title>
 <statement>
<p>Construct a probability histogram for the probability distribution
<me>f(x) = \dfrac{{2\choose x}{4\choose{3-x}}}{{6\choose3}} \text{ for
}x=0, 1, 2</me>
 </p>
 </statement>
 </exercise>
 
   <exercise>
 <title>Problem 3.87</title>
 <statement>
 <p> The probability distribution of <m>V</m>, the number of weekly
accidents at a certain intersection, is given by <m>g(0) = 0.4, g(1) =
0.3, g(2) = 0.2, g(3) = 0.1</m>. Construct the distribution function of
<m>V</m> and draw its graph.
</p>
 </statement>
 </exercise>
 
    <exercise>
 <title>Problem 3.88</title>
 <statement>
 <p> Using the statement and result of the previous problem, find the probability
that there will be at least two accidents in any one week using 
<ol>
<li><p>the original probabilities, and </p></li>
<li><p>the values of the distribution function.</p></li>
</ol>
</p>
 </statement>
 </exercise>
 
</exercises>

<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-multi-variable">
<title>Multivariate, marginal, and conditional distributions</title>
<introduction>
<p> See sections 3.5, 3.6, 3.7. Recommended problems: (pg 101) 42, 44, 45, 49, 53, 54</p></introduction>

<definition xml:id="def-joint-probability-distribution-3-6">
<title>joint probability distribution</title>
<statement>
<p>
If <m>\displaystyle X</m> and <m>\displaystyle Y</m> are discrete
random variables, the function given by <m>\displaystyle f(x,y) = P(X=x,
Y=y)</m> for each pair of values <m>\displaystyle (x,y)</m> within the
range of <m>\displaystyle X</m> and <m>\displaystyle Y</m> is called the
<term>joint probability distribution</term> of <m>\displaystyle X</m>
and <m>\displaystyle Y</m>.
</p>
</statement></definition>

<theorem xml:id="thm-3-7">
<title>conditions for a joint probability distribution</title>
<statement>
<p> A bivariate function can serve as a joint probability distribution
for a pair of discrete random variables <m>\displaystyle X</m> and
<m>\displaystyle Y</m> if and only if its values, <m>\displaystyle f(x,
y)</m>, satisfy the conditions
<ol>
<li> <m>\displaystyle f(x, y) \ge 0</m> for each pair of values
<m>\displaystyle (x, y)</m> within its domain;</li>
<li> <m>\displaystyle \sum_x\sum_y f(x, y) = 1</m> where the double
summation extends over all possible pairs <m>\displaystyle (x,
y)</m>.</li>
</ol>
</p>
</statement></theorem>


<definition xml:id="def-joint-distribution-function-3-7">
<title>joint distribution function</title>
<statement>
<p>
If <m>\displaystyle X</m> and <m>\displaystyle Y</m> are discrete random
variables, the function given by <me>F(x, y) = P(X \le x, Y \le y) =
\sum_{s\le x} \sum_{t\le y} f(s, t) \text{ for } \infty \lt x, y \lt
\infty</me> where <m>\displaystyle f(s, t)</m> is the value of the joint
probability distribution of <m>\displaystyle X</m> and <m>\displaystyle
Y</m> at <m>\displaystyle (s, t)</m>, is called the <term>joint
distribution function</term> or <term>joint cumulative
distribution</term> of <m>\displaystyle X</m> and <m>\displaystyle
Y</m>.
</p>
</statement></definition>

<definition xml:id="def-marginal-distribution-3-10">
<title>marginal distribution</title>
<statement>
<p>
If <m>\displaystyle X</m> and <m>\displaystyle Y</m> are discrete random
variables and <m>\displaystyle f(x, y)</m> is the value of their joint
probability distribution at <m>\displaystyle (x, y)</m>, the function
given by <me>g(x) = \sum_y f(x, y)</me> for each <m>\displaystyle x</m>
within the range of <m>\displaystyle X</m> is called the <term>marginal
distribution</term> of <m>\displaystyle X</m>. Correspondingly, the
function given by <me>h(y) = \sum_x f(x, y)</me> for each
<m>\displaystyle y</m> within the range of <m>\displaystyle Y</m> is
called the <term>marginal distribution</term> of <m>\displaystyle Y</m>.

</p>
</statement></definition>

<definition xml:id="def-conditional-distribution-3-10">
<title>conditional distribution</title>
<statement>
<p>
<term>conditional distribution</term>
<me>f(x|y) = \dfrac{f(x, y)}{h(y)}, h(y)\ne 0</me>
<me>w(y|x) = \dfrac{f(x, y)}{g(x)}, g(x)\ne 0</me>
</p>
</statement></definition>
</subsection>

<!-- Recommended problems: (pg 101) discrete: 42, 44, 45; continuous: 49, 53, 54 -->
<exercises>
 <exercise>
 <title>Problem 3.42</title>
 <statement>
 <p>If the values of the joint probability distribution of \(X\) and \(Y\) are shown below,
<me>\begin{aligned}[t]
P[x=0, y=0] \amp = \frac{1}{12}\\
P[x=1, y=0] \amp = \frac{1}{6}\\
P[x=2, y=0] \amp = \frac{1}{24}\\
P[x=0, y=1] \amp = \frac{1}{4}\\
P[x=1, y=1] \amp = \frac{1}{4}\\
P[x=2, y=1] \amp = \frac{1}{40}\\
P[x=0, y=2] \amp = \frac{1}{8}\\
P[x=1, y=2] \amp = \frac{1}{20}\\
P[x=0, y=3] \amp = \frac{1}{120}\\
\end{aligned}
</me>
find 
<ol>
<li><p>(b) <m>P(X = 0, 1\le Y \lt 3)</m></p></li>
<li><p>(c) <m>P(X + Y \le 1)</m></p></li>
<li><p>(d) <m>P(X \gt Y)</m></p></li>
</ol>

 </p>
 </statement>
 </exercise>
 
  <exercise>
 <title>Problem 3.44</title>
 <statement>
 <p>If the joint probability distribution of <m>X</m> and <m>Y</m> is given by <me>f(x, y) = c(x^2+y^2) \text{ for } x=0, 3; y=0, 1, 2</me>
find the value of <m>c</m>.</p>
 </statement>
 </exercise>
 
   <exercise>
 <title>Problem 3.45</title>
 <statement>
 <p>With references to the previous problem find
 <ol>
<li><p> <m>P(X\le 1, Y \gt 2)</m></p></li>
<li><p> <m>P(X=0, Y\le 2)</m></p></li>
<li><p> <m>P(X +Y \gt 2)</m></p></li>
</ol>
</p>
 </statement>
 </exercise>

   <exercise>
 <title>Problem 3.70</title>
 <statement>
 <p>With reference to 3.42, find 
 <ol>
<li><p> the marginal distribution of <m>X</m></p></li>
<li><p> the marginal distribution of <m>X</m></p></li>
<li><p> the conditional distribution of <m>X</m> given <m>Y=1</m></p></li>
<li><p> the conditional distribution of <m>Y</m> given <m>X=0</m></p></li>
</ol>
</p>
 </statement>
 </exercise>




 
</exercises>

</section>

<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->


<section xml:id="section-discrete-expectation">
<title>Mathematical expectation of discrete random variables</title>

<introduction>
<p> This is the start of Chapter 4 in Freund's Mathematical Statistics.
In the first pass we will study the major topics of this chapter with a
focus on those applying to discrete random variables. </p>
</introduction>

<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-expectation">
<title>Expected value</title>
<p>See section 4.1 - 4.2. Recommended problems: (pg 136) 7, 9, 10, 11, (pg 161) 60
</p>

<definition xml:id="def-expected-value-4-1">
<title>expected value</title>
<statement>
<p>
If <m>\displaystyle X</m> is a discrete random variable and
<m>\displaystyle f(x)</m> is the value of its probability distribution
at <m>\displaystyle x</m>, the <term>expected value</term> of
<m>\displaystyle X</m> is given by
<me> E[X] = \sum_x x\cdot f(x)</me>
</p>
</statement></definition>

<theorem xml:id="thm-expected-value-function-random-variable-4-1">
<title>expected value of a function of a random variable</title>
<statement>
<p>
If <m>\displaystyle X</m> is a discrete random variable and
<m>\displaystyle f(x)</m> is the value of its probability distribution
at <m>\displaystyle x</m>, the expected value of <m>\displaystyle
g(X)</m> is given by
<me>E[g(X)] = \sum_x g(x)\cdot f(x)</me>
</p>
</statement></theorem>

<theorem xml:id="thm-4-2">
<title>expectation of a linear function</title>
<statement>
<p> If <m>\displaystyle a</m> and <m>\displaystyle b</m> are constants,
then
<m>\displaystyle E[aX +b] = aE[X]+b</m>.
</p>
</statement></theorem>

<corollary xml:id="cor-4-1">
<statement>
<p> If a is a constant, then
<m>\displaystyle E[aX] = aE[X]</m>.
</p>
</statement></corollary>

<corollary xml:id="cor-4-2">
<statement>
<p>If b is a constant, then
<m>\displaystyle E[b] = b</m>.
</p>
</statement></corollary>

<theorem xml:id="thm-expected-value-joint-random-variables-4-4">
<title>expected value of joint random variables</title>

<statement>
<p>
If <m>\displaystyle X</m> and <m>\displaystyle Y</m> are discrete random
variables and <m>\displaystyle f(x, y)</m> is the value of their joint
probability distribution at <m>\displaystyle (x, y)</m>, the expected
value of <m>\displaystyle g(X, Y)</m> is given by
<me>E[g(X, Y)] = \sum_x \sum_y g(x, y)\cdot f(x,y)</me>
</p>
</statement></theorem>

<theorem xml:id="thm-4-5">
<title>expected value of a linear combination of random variables</title>
<statement>
<p> If <m>\displaystyle c_1, c_2, \dots, c_n</m> are constants, then
<me>E\left[\sum_{i=1}^n c_i g_i(X_1, X_2, \dots, X_k)\right] =
\sum_{i=1}^n c_i E\left[g_i(X_1, X_2, \dots, X_k)\right]</me>
</p>
</statement></theorem>

</subsection>

<!-- See section 4.1 - 4.2. Recommended problems: (pg 136) disc: 9, (pg 161) 60, cont: 7, 10, 11 -->
<exercises>
 <exercise>
 <title>Problem 4.9</title>
 <statement>
 <p>Suppose that <m>X</m> takes on values <m>0, 1, 2, 3</m> with
probabilities <m>\dfrac{1}{125}, \dfrac{12}{125}, \dfrac{48}{125},
\dfrac{64}{125}</m>
  <ol>
<li><p> Find <m>E[X]</m> and <m>E[X^2]</m></p></li>
<li><p> Determine the value of <m>E[(3X + 2)^2]</m></p></li>
</ol>
 </p>
 </statement>
 </exercise>
 
 
 
</exercises>

<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-moments">
<title>Expected value</title>
<p>See section 4.3. Recommended problems: 4.3 (pg 146) 20, 22, 23, 31, 33, 34, 40, (pg 162) 69, 73, 75
</p>

<definition xml:id="def-moments-about-origin-4-2">
<title>moments about the origin</title>
<statement>
<p>
The <m>\displaystyle r^\text{th}</m> <term>moment about the
origin</term> of a random variable <m>\displaystyle X</m>, denoted by
<m>\displaystyle \mu_r'</m>, is the expected value of <m>\displaystyle
(X)^r</m>; symbolically
<me>\mu_r'=E[(X)^r] = \sum_x x^r\cdot f(x)</me> for <m>\displaystyle r =
0,1,2, \dots</m> when <m>\displaystyle X</m> is discrete.
</p>
</statement></definition>

<definition xml:id="def-mean-4-3">
<title>mean of a discrete random variable</title>
<statement>
<m>\displaystyle \mu_1'</m> is called the <term>mean</term> of the
distribution of <m>\displaystyle X</m>, or simply the <term>mean</term>
of <m>\displaystyle X</m>; and it is denoted by <m>\displaystyle
\mu</m>.
</statement></definition>

<definition xml:id="def-moments-about-mean-4-4">
<title>moments about the mean</title>
<statement>
<p>
The <m>\displaystyle r^\text{th}</m> <term>moment about the
mean</term> of a random variable <m>\displaystyle X</m>, denoted by
<m>\displaystyle \mu_r</m>, is the expected value of <m>\displaystyle
(X-\mu)^r</m>; symbolically
<me>\mu_r=E[(X-\mu)^r] = \sum_x (x-\mu)^r\cdot f(x)</me> for
<m>\displaystyle r =
0,1,2, \dots</m> when <m>\displaystyle X</m> is discrete.
</p>
</statement></definition>

<p>
Now, you could imagine in some cases the moments being difficult to
calculate as sums. We sometimes take the approach of building what are
called moment-generating functions. These are mathematical functions
whose purpose is to generate the moments of a distribution that we might
need.</p>


</subsection>

<!-- Recommended problems: 4.3 (pg 146) disc: 23; cont: 20, 22, 31, -->
<exercises>
 <exercise>
 <title>Problem 4.18</title>
 <statement>
 <p>Find <m>\mu</m>, <m>\mu_2'</m>, and <m>\sigma^2</m> for the random
variable <m>X</m> that has probability distribution <m>f(x) = 0.5 \text{
for } x= \pm 2</m>.
 </p>
 </statement>
 </exercise>
 
</exercises>

<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-mgf">
<title>Moment-generating functions</title>
<p>See section 4.5.</p>

<definition xml:id="def-mgf-4-6">
<title>moment-generating function</title>

<statement>
<p> The <term>moment-generating function</term> of a random variable
<m>\displaystyle X</m>, where it exists, is given by <me>\displaystyle
M_X(t) = E[e^{tX}] = \sum_x e^{tx}\cdot f(x)</me>
when <m>\displaystyle X</m> is discrete.
</p>
</statement></definition>

<p>
Notce that a moment-generating function <m>\displaystyle M_X(t)</m>
itself is a function of the variable <m>\displaystyle t</m> not
<m>\displaystyle x</m>. As it turns out, we are most interested in
values
of the function at or near <m>\displaystyle t=0</m>.
</p>

<example xml:id="ex-maclaurin">
<title>moment-generating function via Taylor series</title>
<statement>
<p>
Recall that the Maclaurin series (Taylor series around zero) for
<m>\displaystyle e^{tx}</m> is <me>e^{tx} = 1 + tx +
\frac{1}{2!}\left(tx\right)^2 + \frac{1}{3!}\left(tx\right)^3 + \cdots +
\frac{1}{r!}\left(tx\right)^r + \cdots</me>
This means (in the discrete case), that <me>
\begin{aligned}[t]
M_X(t) \amp = \sum_x e^{tx} f(x)\\
\amp = \sum_x \left(1 + tx + \frac{1}{2!}(tx)^2 +
\frac{1}{3!}\left(tx\right)^3 + \cdots + \frac{1}{r!}\left(tx\right)^r +
\cdots\right) f(x)\\
\amp = \sum_x (f(x) + txf(x) + \frac{t^2}{2!}x^2f(x) +
\frac{t^3}{3!}x^3f(x) + \cdots + \frac{t^r}{r!}x^rf(x) + \cdots)\\
\amp = \sum_xf(x) + t\sum_x xf(x) + \frac{t^2}{2!}\sum_x x^2f(x) +
\frac{t^3}{3!}\sum_x x^3f(x) + \cdots + \frac{t^r}{r!}\sum_x x^rf(x) +
\cdots
\end{aligned}
</me>
Looking closely, at <me>M_X(t) = \sum_xf(x) + \left(\sum_x xf(x)\right)t
+ \left(\sum_x x^2f(x)\right)\frac{t^2}{2!} + \left(\sum_x
x^3f(x)\right)\frac{t^3}{3!} + \cdots + \left(\sum_x
x^rf(x)\right)\frac{t^r}{r!} + \cdots</me> coefficients of the terms
<m>\displaystyle \dfrac{t^r}{r!}</m> are the moments about the origin
<m>\displaystyle \mu_r' = \sum_x x^r f(x)</m>

</p>

</statement></example>


<example xml:id="ex-three-cards-mgf">
<title>moment-generating function for three cards</title>

<statement>
<p>
Recall the probability distribution <m>f(x) = P(X = x) =
\dfrac{{3\choose x}}{8} \text{ for } x = 0, 1, 2, 3</m> (this was used
earlier to determine the probabilities of <m>x</m> heads on three flips
of a coin).
<me>
\begin{aligned}[t]
M_X(t) \amp = \sum_x e^{tx} f(x)\\
\amp = 1 \cdot \frac{1}{8} + e^{t} \cdot \frac{3}{8}+ e^{2t} \cdot
\frac{3}{8} + e^{3t} \cdot \frac{1}{8}\\
\amp = \frac{1}{8} \left(1 + 3e^{t} + 3e^{2t} + e^{3t}\right)\\
M_X(t) \amp = \frac{1}{8} (1+e^t)^3\\
\end{aligned}
</me>
</p>
</statement></example>

<theorem xml:id="thm-4-9">
<title>moments via differentiation</title>
<statement>
<p>
The <m>r^\text{th}</m> moment about the origin, <m> \mu_r'</m>, can be
written
<me>\displaystyle \mu_r' = \dfrac{d^rM_X(t)}{dt^r}\Big|_{t=0}</me>
</p>
</statement></theorem>

<example xml:id="ex-three-cards-mgf2">
<title>moment-generating function for three cards, via differentiation</title>
<statement>
<p>
Referencing Example <xref ref="ex-three-cards-mgf"/>, the mean of the
random variable, given by <m>\mu_1'</m>, whose MGF is <m>M_X(t) =
\frac{1}{8} (1+e^t)^3</m> is found as follows
<me>
\begin{aligned}[t]
\mu_1' \amp = \left(\dfrac{d}{dt}\left(\frac{1}{8}
(1+e^t)^3\right)\right)\Big|_{t=0}\\
	 \amp = \left(\frac{3}{8} (1+e^t)^2e^t\right)\Big|_{t=0}\\
\amp = \left(\frac{3}{8} (2)^2\right)\\
\mu_1' \amp = \frac{3}{2}
\end{aligned}
</me>
</p>
</statement></example>

<p> So, <em>given</em> a moment-generating function, a relatively
simple application of calculus allows us to replace a more tedious
calculation of the moment from its definition.
</p>
<theorem xml:id="thm-4-10">
<title>moment-generating function of functions of a random variable</title>

<statement>
<p>
If <m>\displaystyle a</m> and <m>\displaystyle b</m> are constants, then

<ol>
<li><m>\displaystyle M_{X+a}(t) = E[e^{(X+a)t}] = e^{at} \cdot
M_X(t)</m>;</li>
<li><m>\displaystyle M_{bX}(t) = E[e^{bXt}] = M_X(bt)</m>;</li>
<li><m>\displaystyle M_{\frac{X+a}{b}}(t) =
E\left[e^{\left(\frac{X+a}{b}\right)t}\right] = e^{(a/b)t} \cdot
M_X\left(\frac{t}{b}\right)</m>;</li>
</ol>
</p>
</statement></theorem>
<p>The rules in <xref ref="thm-4-10"/> allow us to calculate
moment-generating functions of simple functions of a random
variable.</p>

</subsection>

<exercises>
 
 
 <exercise>
 <title>Problem 4.33</title>
 <statement>
 <p>Find the moment-generating function of the discrete random variable
<m>X</m> that has the probability distribution <me>f(x) =
2\left(\dfrac{1}{3}\right)^x \text{ for } x = 1, 2, 3, \dots</me> and
use it to determine the values of <m>\mu_1'</m> and <m>\mu_2'</m>.
 </p>
 </statement>
 </exercise>
 
<exercise>
<title>Problem 4.40</title>
<statement>
 <p>Given the moment-generating function <m> X_X(t) = e^{3t+8t^2}</m>,
find the moment generating function of the random variable <m> Z =
\dfrac{1}{4}\left(X-3\right)</m> and use it to determine the mean and
variance of <m>Z</m>.
 </p>
 </statement>
 </exercise>
</exercises>


<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-product-moments">
<title>Product moments</title>
<p>See section 4.6.</p>


<definition xml:id="def-product-moments-origin-4-7">
<title>product moments about the origin</title>

<statement>
<p> The <term><m>\displaystyle r^\text{th}</m> and <m>\displaystyle
s^\text{th}</m> product moment about the origin</term> of the random
variables
<m>\displaystyle X</m> and <m>\displaystyle Y</m>, denoted by
<m>\displaystyle \mu_{r,s}</m>, is the expected value of
<m>\displaystyle X^rY^s</m>; symbolically 
<me>\mu_{r,s}'=E[X^rY^s] = \sum_x\sum_y x^r y^s\cdot f(x, y)</me>
<m>\displaystyle r = 0,1,2, \dots</m> and <m>\displaystyle s = 0,1,2,
\dots</m>
when <m>\displaystyle X</m> and Y are discrete.</p>
</statement></definition>

<p>
Special cases of product moments are <m>\displaystyle \mu_{1,0}' =
E[X^1Y^0] = E[X] = \mu_X</m> and <m>\displaystyle \mu_{0,1}' = E[X^0Y^1]
= E[Y] = \mu_Y</m>.
</p>

<p>
As complicated as the definitions of the product moments may be, they
lead to a way to define and calculate the very important concept of
covariance.
<ul>
<li> If we have a high probability of large <m>\displaystyle X</m>
paired with large <m>\displaystyle Y</m> and small <m>\displaystyle
X</m> paired with small <m>\displaystyle Y</m>, <m>\displaystyle
\operatorname{cov}(X,Y) \gt 0</m></li>
<li> If we have a high probability of large <m>\displaystyle X</m>
paired with small <m>\displaystyle Y</m> and small <m>\displaystyle
X</m> paired with large <m>\displaystyle Y</m>, <m>\displaystyle
\operatorname{cov}(X,Y) \lt 0</m></li>
</ul>
</p>

<definition xml:id="def-product-moments-mean-4-8">
<title>product moments about the mean</title>

<statement>
<p> The <term><m>\displaystyle r^\text{th}</m> and <m>\displaystyle
s^\text{th}</m> product moment about the mean</term> of the random
variables
<m>\displaystyle X</m> and <m>\displaystyle Y</m>, denoted by
<m>\displaystyle \mu_{r,s}'</m>, is the expected value of
<m>\displaystyle (X-\mu_X)^r(Y-\mu_Y)^s</m>; symbolically 
<me>\mu_{r,s}=E[(X-\mu_X)^r(Y-\mu_Y)^s] = \sum_x\sum_y (x-\mu_X)^r
(y-\mu_Y)^s\cdot f(x, y)</me> <m>\displaystyle r = 0,1,2, \dots</m> and
<m>\displaystyle s = 0,1,2, \dots</m>
when <m>\displaystyle X</m> and Y are discrete.
</p>
</statement></definition>

<definition xml:id="def-covariance-4-9">
<title>covariance</title>

<statement>
<p>
<m>\displaystyle \mu_{1,1}</m> is called the <term>covariance</term> of
<m>\displaystyle X</m> and <m>\displaystyle Y</m>, and it is denoted by
<m>\displaystyle \sigma_{XY}</m> or <m>\displaystyle
\operatorname{cov}(X, Y)</m>, or <m>\displaystyle C(X, Y)</m>.
</p>
</statement></definition>

<theorem xml:id="thm-4-11">
<title>covariance from moments about the origin</title>
<statement>
<p>
<m>\displaystyle \sigma_{XY} = \mu_{1,1}' - \mu_X \mu_Y</m>
</p>
</statement></theorem>

<theorem xml:id="thm-4-12">
<title>independence and covariance</title>
<statement>
<p> If <m>\displaystyle X</m> and <m>\displaystyle Y</m> are
independent, then <me>\displaystyle E[XY] = E[X]\cdot E[Y]</me> and
<m>\displaystyle \sigma_{XY} = 0</m>.
</p>
</statement></theorem>

<remark xml:id="rmrk-4-12">
In terms of moments,
<me>\displaystyle\mu_{1,1}' = \mu_{1,0}'\cdot \mu_{0,1}'</me>
</remark>

<theorem xml:id="thm-4-13">
<title>product moments of independent random variables</title>

<statement>
<p> If <m>\displaystyle X_1, X_2, \dots, X_n</m> are independent, then
<m>\displaystyle E[X_1X_2\cdots X_n] = E[X_1]\cdot
E[X_2]\cdot\cdots\cdot E[X_n]</m>.
</p>
</statement></theorem>

<p>Independence means covariance is zero, but covariances of zero does
not mean independence.
</p>

</subsection>

<exercises>
 <exercise>
 <title>Problem 4.41</title>
 <statement>
 <p>If <m>X</m> and <m>Y</m> have the joint probability distribution
<m>f(x, y) = \dfrac{1}{4}</m> for <m>(-3, -5)</m>,  <m>(-1, -1)</m>, 
<m>(1, 1)</m>,  <m>(3, 5)</m>, find <m>\operatorname{cov}(X, Y)</m>.
 </p>
 </statement>
 </exercise>
 
 <exercise>
 <title>Problem 4.45</title>
 <statement>
 <p>If <m>X</m> and <m>Y</m> have the joint probability distribution
 <m>f(-1, 0) = 0</m>,  <m>f(-1, 1) = \dfrac{1}{4}</m>, 
<m>f(0, 0) = \dfrac{1}{6}</m>, <m>f(1, 0) = \dfrac{1}{12}</m>, <m>f(1,
1) = \dfrac{1}{2}</m> show that
<ol>
<li><p> <m>\operatorname{cov}(X, Y) = 0</m>;</p></li>
<li><p> the two random variables are not independent.</p></li>
</ol>
 </p>
 </statement>
 </exercise>
 
 </exercises>

<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-moments-linear-combinations">
<title>Moments of linear combinations of random variables</title>
<introduction>
<p>See section 4.7. Recommended problems: 4.7-8 (pg 158) 48, 49, 57 </p>
</introduction>

<theorem xml:id="thm-4-14">
<title>variance</title>
<statement>
<p> If <m>\displaystyle X_1, X_2, \dots, X_n</m> are random variables
and <m>\displaystyle Y = \sum_{i=1}^n a_iX_i</m> where <m>\displaystyle
a_1, a_2, \dots, a_n</m> are constants, then <me> E[Y] = \sum_{i=1}^n
a_iE[X_i]</me>
and <me>\operatorname{var}[Y] = \sum_{i=1}^n a_i^2
\operatorname{var}[X_i] + 2 \mathop{\sum \sum}_{i \lt j} a_i
a_j\operatorname{cov}[X_i,X_j]</me>.
</p>
</statement></theorem>

<corollary xml:id="cor-4-3">
<title>variance of independent random variables</title>
<statement>
<p>
If <m>\displaystyle X_1, X_2, \dots, X_n</m> are independent random
variables and <m>\displaystyle Y = \sum_{i=1}^n a_iX_i</m> where
<m>\displaystyle a_1, a_2, \dots, a_n</m> are constants, then
<me>\operatorname{var}[Y] = \sum_{i=1}^n
a_i^2\operatorname{var}[X_i]</me>
</p>
</statement></corollary>

<example xml:id="ex-var-covar">
<title>covariances of linear combinations</title>
<statement>
<p>
Consider three random variables <m>X</m>, <m>Y</m>, and <m>Z</m> with
<m>\mu_X = 2</m>, with <m>\mu_Y = -3</m>, with <m>\mu_Z = 4</m>; 
with <m>\sigma_X^2 = 1</m>, <m>\sigma_Y^2 = 5</m>, <m>\sigma_Z^2 =
2</m>; 
and <m>\operatorname{cov}(X, Y) = -2</m>, <m>\operatorname{cov}(X, Z) =
-1</m>, and <m>\operatorname{cov}(Y, Z) = 1</m>.
</p>

<p>Find <m>\mu_W</m> and <m>\operatorname{var}(W) = \sigma_W^2</m> for
<m>W = 3X-Y+2Z</m>.</p>

<solution>
<p> First, <m>\mu_W = (3)\mu_X + (-1)\mu_Y + (2)\mu_Z = 17</m>.
</p>

<p>We could apply the theorem directly, but we can do this more directly
with linear algebra. The idea is that we can picture the linear
combination <m>W = 3X-Y+2Z</m> as <me>W =
\left[\begin{array}{ccc}3 \amp -1 \amp
2\end{array}\right]\cdot\left[\begin{array}{c}X \\Y\\
Z\end{array}\right] = (3)X + (-1)Y + (2)Z
</me></p>

<p>
Let <m>a</m> be the row vector <m>a = \left[\begin{array}{ccc}3 \amp -1
\amp 2\end{array}\right]</m>, 
its transpose be the column vector <m>a^T</m>, and the matrix
<m>\Sigma</m> be defined as follows,
<me>\Sigma = \left[\begin{array}{ccc}
1 \amp -2 \amp -1\\
-2 \amp 5 \amp 1\\
-1 \amp 1 \amp 2
\end{array}\right]
</me>
</p>

<p>
This approach can be justified by expanding the sums in <xref
ref="thm-4-14"/> with a sum of 2 random variables. 
</p>

<p>We can calculate the variance of <m>W</m> by <m>\operatorname{var}(W)
= a\Sigma a^T</m>. 
Specifically, <me>a \Sigma a^T = \left[\begin{array}{ccc}3 \amp -1 \amp
2\end{array}\right]\cdot\left[\begin{array}{ccc}
1 \amp -2 \amp -1\\
-2 \amp 5 \amp 1\\
-1 \amp 1 \amp 2
\end{array}\right]\cdot\left[\begin{array}{c}3 \\-1\\
2\end{array}\right]
</me>
</p>

<p>Notice <m>Sigma</m> is symmetric and that the covariances lie in
order along the main diagonal and the variances off-diagonal.</p>

<p>Multiplying the square matrix and column vector first, we have 
<me>a \Sigma a^T = \left[\begin{array}{ccc}3 \amp -1 \amp
2\end{array}\right]\cdot\left[\begin{array}{c}3 \\-9\\
0\end{array}\right]
</me></p>

<p>And finally, <m>a \Sigma a^T = 18</m>.</p>

</solution>
</statement></example>

<theorem xml:id="thm-4-15">
<title>covariance of two linear combinations</title>

<statement>
<p>
If <m>\displaystyle X_1, X_2, \dots, X_n</m> are random variables and
<m>\displaystyle Y_1 = \sum_{i=1}^n a_i X_i \text{ and } Y_2 =
\sum_{i=1}^n b_iX_i</m> where <m>\displaystyle a_1, a_2, \dots, a_n,
b_1, b_2, \dots, b_n</m> are constants, then <me>\operatorname{cov}[Y_1,
Y_2] = \sum_{i=1}^n a_i b_i\operatorname{var}[X_i] + \mathop{\sum
\sum}_{i \lt j} (a_ib_j + a_jb_i)\operatorname{cov}[X_i,X_j]</me>.
</p>
</statement></theorem>

<corollary xml:id="cor-4-3b">
<statement>
<p>
If <m>\displaystyle X_1, X_2, \dots, X_n</m> are independent random
variables and
<m>\displaystyle Y_1 = \sum_{i=1}^n a_iX_i \text{ and } Y_2 =
\sum_{i=1}^n b_iX_i</m>, then <me>\operatorname{cov}[Y_1, Y_2] =
\sum_{i=1}^n a_i b_i\operatorname{var}[X_i]</me>
</p>
</statement></corollary>

The same logic used in <xref ref="ex-var-covar"/> allows us to compute
the covariance between two linear combinations of random variables
directly also. Instead of calculating <m>a\Sigma a^T</m> we will
calculate <m>a \Sigma b^T</m> where <m>b</m> is the vector of
coefficients of the second linear combination.

</subsection>
<exercises>

 
  <exercise>
 <title>Problem 4.48</title>
 <statement>
 <p>If <m>X_1</m>, <m>X_2</m>, <m>X_3</m> are independent and have the
means <m>4, 9, 3</m> and the variances <m>3, 7, 5</m>, find the mean and
variance of  show that
<ol>
<li><p> <m>Y = 2X_1 - 3X_2 + 4X_3</m>;</p></li>
<li><p> <m>Z = X_1 + 2X_2 -X_3</m>.</p></li>
</ol>
 </p>
 </statement>
 </exercise>
 
   <exercise>
 <title>Problem 4.49</title>
 <statement>
 <p>Repeat both parts of the previous exercise after dropping the
assumption of independence and using instead that
<m>\operatorname{cov}(X_1, X_2) = 1</m>, <m>\operatorname{cov}(X_2, X_3)
= -2</m>, <m>\operatorname{cov}(X_1, X_3) = -3</m>.
 </p>
 </statement>
 </exercise>
 
 
</exercises>

<!-- *********************************** -->
<!-- *********************************** -->
<!-- *********************************** -->

<subsection xml:id="sub-conditional-expectation">
<title>Conditional expectation</title>
<p>See section 4.8.</p>


<definition xml:id="def-conditional-expectation-4-10">
<title>conditional expectation</title>
<statement>
<p>If <m>\displaystyle X</m> is a discrete random variable and
<m>\displaystyle f(x|y)</m> is the value of the conditional probability
distribution of <m>\displaystyle X</m> given <m>\displaystyle Y = y</m>
at <m>\displaystyle x</m>, the <term>conditional expectation</term> of
<m>\displaystyle u(X)</m> given <m>\displaystyle Y = y</m> is 
<me>E[u(X)|y] = \sum_x u(x)\cdot f(x|y)</me> and the <term>conditional
expectation</term> of <m>\displaystyle v(Y)</m> given <m>\displaystyle X
= x</m> is 
<me>E[v(Y)|x] = \sum_y v(y)\cdot w(y|x)</me>
</p>
</statement></definition>

<definition xml:id="def-conditional-mean">
<title>conditional mean</title>
<statement>
<p> If <m>\displaystyle X</m> is a discrete random variable and
<m>\displaystyle f(x|y)</m> is the value of the conditional probability
distribution of <m>\displaystyle X</m> given <m>\displaystyle Y = y</m>
at <m>\displaystyle x</m>, the <term>conditional mean</term> of
<m>\displaystyle u(X) = X</m> given <m>\displaystyle Y = y</m> is 
<me>\mu_{X|y} = E[X|y] = \sum_x x\cdot f(x|y)</me> and the
<term>conditional mean</term> of <m>\displaystyle v(Y) = Y</m> given
<m>\displaystyle X = x</m> is 
<me>\displaystyle \mu_{Y|x} = E[Y|x] = \sum_y y\cdot w(y|x)</me>
</p>
</statement></definition>

<definition xml:id="def-conditional-variance">
<title>conditional variance</title>
<statement>
<p>If <m>\displaystyle X</m> is a discrete random variable and
<m>\displaystyle f(x|y)</m> is the value of the conditional probability
distribution of <m>\displaystyle X</m> given <m>\displaystyle Y = y</m>
at <m>\displaystyle x</m>, the <term>conditional variance</term> of
<m>\displaystyle X</m> given <m>\displaystyle Y = y</m> is 
<me>\sigma^2_{X|y} = E[(X-\mu_{X|y})^2|y] = E[X^2]-\mu^2_{X|y}</me> and
the <term>conditional expectation</term> of <m>\displaystyle Y</m> given
<m>\displaystyle X = x</m> is 
<me>\displaystyle\sigma^2_{Y|x} = E[(Y-\mu_{Y|x})^2|y] =
E[Y^2]-\mu^2_{Y|x}</me>
</p>
</statement>
</definition>


</subsection>

<!-->
<exercises>
 <exercise>
 <title>4.xx</title>
 <statement>
 <p>xx
 </p>
 </statement>
 </exercise>
 
</exercises>
-->
</section>

<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... section-special-distributions ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->
<!-- ....... .............. .............. ....... -->

<section xml:id="section-special-distributions">
<title>Special probability distributions</title>

<introduction>
<p> Now we look at a collection of formulas for probability
distributions. These describe how probabilities are assigned across a
range of discrete values of a random variable. It turns out to be the
case that values of random variables associated with certain kids of
experiments follow certain formulas. In this chapter, we will look at
the formulas that describe certain discrete random variables. </p>
<p> For the purposes of generality we will emphasize that certain
formulas include one or more parameters, these are symbols to which we
will associate particular numerical values, much like we do <m>m</m> and
<m>b</m> in the formula <m>y = f(x) = mx+b</m>. We should have a general
understanding of something that follows this relationship and an
understanding of the roles of both <m>m</m> and <m>b</m> in specifying
that relationship. </p>
</introduction>

<!-- ....... .............. .............. ....... -->
<!-- ....... discrete-unif ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-discrete-unif">
<title>Discrete uniform</title>

<definition xml:id="def-discrete-unif">
<title>discrete uniform distribution</title>

<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>discrete uniform distribution</term> and is referred to as a
<term>discrete uniform random variable</term> if and only if its
probability distribution is given by <me>f(x) = \frac{1}{k} \text{ for }
x = x_1, x_2, \dots, x_k \text{ where }x_i\ne x_j \text{ for } i \ne
j</me>.
</p>
</statement></definition>

<p> This is sometimes written as <m>\operatorname{DU}(k)</m>, where
<m>k</m> is the parameter of the distribution.</p>

<example xml:id="ex-disc-unif-mean"> 
<title>mean of a discrete uniform distribution</title>

<statement>
<p>Find the mean of a discrete uniform random variable (or of the
discrete uniform distribution).</p>
<solution>
<p>Recall that <me>f(x) = \frac{1}{k} \text{ for } x = x_1, x_2, \dots,
x_k \text{ where }x_i\ne x_j \text{ for } i \ne j</me> and that <me>\mu
= \sum_x x\cdot f(x)</me>. This becomes <me>\mu = \sum_{i=1}^k
x_i\left(\frac{1}{k}\right)</me>. This is about as far as we can go in
general without knowing more about <m>k</m> or the values of <m>x_i</m>.
</p>
</solution>
</statement></example>

<p>Similar to the previous "Example", the variance of a discrete uniform
random variable (or of the discrete uniform distribution) is given by
<me>\sigma^2 = \sum_x (x-\mu)^2\cdot f(x)= \sum_x (x-\mu)^2
\left(\frac{1}{k}\right)</me>. Once again, this is about as far as we
can go in general.
</p>

<example xml:id="ex-disc-unif-simple">
<title>simple discrete uniform distribution</title>
<statement>
<p>Find the mean of a discrete uniform random variable (or of the
discrete uniform distribution) for which <m>x_i = i</m>.</p>
<solution>
<p>Recall that <me>f(x) = \frac{1}{k} \text{ for } x = 1, 2, \dots,
k</me> and that <me>\mu = \sum_x x\cdot f(x)</me>.
This becomes <me>
\begin{aligned}[t]
\mu \amp = \sum_{i=1}^k i\left(\frac{1}{k}\right)\\
	\amp = \frac{1}{k}\left(\sum_{i=1}^k i\right)\\
	\amp = \frac{1}{k}\left(\dfrac{k(k+1)}{2}\right)\\
\mu	\amp = \dfrac{k+1}{2}
\end{aligned}</me>. Now, verify our earlier work on the mean number of
dots to show on a balanced, 6-sided die.
</p>
</solution>
</statement></example>

</subsection>
<exercises>
 <exercise>
 <title>5.2</title>
 <statement>
 <p>If <m>X</m> has a discrete uniform distribution <m>f(x) = \dfrac{1}{k}</m> for <m>x = 1, 2, \dots, k</m>, show that 
its moment-generating function is given by <me>M_x(t) = \dfrac{e^t(1-e^{kt})}{k(1-e^t)}</me>.
<!--> <ol>
 <li><p>its mean is <m>\mu = \dfrac{}</m></p></li>
 <li><p><m></m></p></li>
  </ol>-->
 </p>
 </statement>
 </exercise>
 
</exercises>

<!-- ....... .............. .............. ....... -->
<!-- ....... bern-bin ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-discrete-bern-bin">
<title>Bernoulli and Binomial distributions</title>

<introduction>
<p> Consider an experiment with two possible outcomes, flipping a coin
for example. We consider one of those outcomes, say 'heads' as a
success, and the other of those outcomes, in this case 'tails` as a
failure. We allow these outcomes to each occur with a given probability.
Here <m>\theta</m> gives the probability of 'success' and
<m>1-\theta</m> is the corresponding probability of 'failure'.</p>

<p>Though the outcome of a single event may be useful, the Bernoulli
distribution is perhaps most useful as a building block to describe the 
results of more complex experiments.</p>

<p>You will find tools for visualization at the following <url href="https://buddy.uco.edu/shiny/slaverty/mathstat/Binomial/"> link</url>.</p>

</introduction>

<definition xml:id="def-bern">
<title>Bernoulli distribution</title>

<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>Bernoulli distribution</term> and is referred to as a
<term>Bernoulli random variable</term> if and only if its probability
distribution is given by <me>f(x; \theta) = \theta^x(1-\theta)^{1-x}
\text{ for }x = 0, 1</me>.
</p>
</statement></definition>

<example xml:id="ex-bern-mean-var"> 
<title>mean and variance of a Bernoulli distribution</title>
<statement>
<p>Find the mean and variance of a Bernoulli random variable (or of the
Bernoulli distribution).</p>
<solution>
<p>Generally we calculate the mean as <me>\mu = \sum_x x\cdot f(x)</me>.

Specifically this becomes <me>\begin{aligned}[t]
\mu \amp = \sum_{i=0}^1 x f(x; \theta)\\
\amp = 0\left(\theta^0(1-\theta)^1\right) +
1\left(\theta^1(1-\theta)^0\right)\\
\mu \amp = \theta
\end{aligned}</me>.
</p>

<p>We calculate the variance as <m> \sigma^2 =
E[X^2]-\left(E[X]\right)^2</m>. Keep in mind that we now know that
<m>E[X] = \theta</m>, so we know that <m>\left(E[X]\right)^2 =
\theta^2</m>
</p>
<p> Now <me>\begin{aligned}[t]
E[X^2] \amp = \sum_{i=0}^1 x^2 f(x; \theta)\\
\amp = 0^2\left(\theta^0(1-\theta)^1\right) +
1^2\left(\theta^1(1-\theta)^0\right)\\
E[X^2] \amp = \theta
\end{aligned}</me> Given this, <me>\begin{aligned}[t]
\sigma^2 \amp = E[X^2]-\left(E[X]\right)^2\\
\amp = \theta - \theta^2 \\
\sigma^2 \amp = \theta(1-\theta)
\end{aligned}</me>
</p>
</solution>
</statement></example>

<example xml:id="ex-bern-mgf"> 
<title>moment-generating function of a Bernoulli distribution</title>

<statement>
<p>Find the moment-generating function of a Bernoulli random variable
(or of the Bernoulli distribution).</p>
<solution>
<p>Recall that <m>\displaystyle M_X(t) = E[e^{tx}] = \sum_x e^{tx} f(x;
\theta)</m>. 
This becomes <me>
\begin{aligned}[t]
M_X(t) \amp = \sum_{x=0}^1 e^{tx} f(x; \theta)\\
\amp = e^{0\cdot t}\left(\theta^0(1-\theta)^1\right) + e^{1\cdot
t}\left(\theta^1(1-\theta)^0\right)\\
\amp = (1-\theta) + \theta e^t\\
M_X(t) \amp = 1 + \theta (e^t-1)
\end{aligned}</me>.
</p>
</solution>
</statement></example>


<p> You could use the moment-generating function and the earlier
theorem to calculate moments about the origin used to find the mean and
variance.</p>

<p> Consider now a new random variable <m>Y</m> whose value is the sum
of independent Bernoulli trials. This new variable has a 'binomial
distribution' as defined below.</p>

<definition xml:id="def-bin">
<title>binomial distribution</title>

<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>binomial distribution</term> and is referred to as a
<term>binomial random variable</term> if and only if its probability
distribution is given by <me>b(x; n, \theta) = {n\choose
x}\theta^x(1-\theta)^{n-x} \text{ for }x = 0, 1, \dots, n</me>.
</p>
</statement></definition>

<p>In the definition, the term <m>\displaystyle {n \choose x}</m> gives
the number of ways to select the order of the <m>x</m> successes in
<m>n</m> trials. The values of <m>b(x; n, \theta)</m> give the
coefficients of terms in the expansion of <m>\displaystyle
\left((1-\theta) + \theta\right)^n</m>.
</p>

<example xml:id="ex-bin-coins"> 
<title>Binomial coin flips</title>

<statement>
<p>Find the probability of 5 heads in 9 coin flips under each of the
following situations.
<ol>
<li>The coin is balanced and <m>P(\text{success}) = P(\text{failure}) =
0.5</m></li>
<li>The coin is unbalanced and <m>P(\text{success})</m> is <m>3</m>
times larger than <m>P(\text{failure})</m></li>
</ol>
</p>

<solution>
This problem can be done by evaluating the binomial using 'Table 1' of
the 'Statistical Tables Appendix' (see book), or by using the definition
of probability distribution of the binomial random variable.
<ol>
<li><p>The coin is balanced and <m>P(\text{success}) = P(\text{failure})
= 0.5</m>. 
We are looking to evaluate the binomial probability, sometimes written
<m>\operatorname{Bin}(n=9, \theta=0.5)</m>, specifically <m>b(5; 9,
0.5)</m>. 
This is, <me>b(5; 9, 0.5) = {9 \choose 5}0.5^5(1-0.5)^{9-5} \approx
0.2461 </me></p></li>
<li><p>The coin is unbalanced and <m>P(\text{success})</m> is <m>3</m>
times larger than <m>P(\text{failure})</m>. 
We first have to figure out the value for <m>P(\text{success}) =
\theta</m>. 
We have said that <m>P(\text{success}) = 3\cdot P(\text{failure})</m> or
<m>\theta = 3\cdot (1-\theta)</m>.
This gives <m>\theta = 0.75</m> and, as above, <me>b(5; 9, 0.75) = {9
\choose 5}0.75^5(1-0.75)^{9-5} \approx 0.1168 </me></p></li>
</ol>

</solution>
</statement></example>

<example xml:id="ex-bin-bball">
<title>Free throws</title>
<statement>
<p> What is the probability of making <m>2</m> in <m>5</m> free throws
if the probability of making one is <m>0.86</m>?
</p>

<solution>
<p>
We need to calculate <me>b(2; 5, 0.86) = {5\choose2}0.86^2(1-0.86)^{5-2}
= 10(0.86)^2(0.14)^3 \approx 0.0203</me>.  This calculation corresponds to the ten
possible orderings of 2 makes in 5 shot attempts, the probabilities
associated with 2 'makes', and the probabilities associated with 3
'misses'.
</p>
</solution>
</statement>
</example>

<p>Switching focus from <m>x</m> successes in <m>n</m> trials with a
probability of success <m>\theta</m>, we have <m>n-x</m> failures in
<m>n</m> trials with a probability of failure <m>1-\theta</m>.</p>

<theorem xml:id="thm-bin-param"> 
<title>reparameterizing a binomial</title>
<statement>
<p>
<me> b(x; n, \theta) = b(n-x; n, 1-\theta)</me>
</p>
</statement></theorem>

<example xml:id="ex-bin-bball2">
<title>Free throws - revisited</title>
<statement>
<p> Using theorem <xref ref="thm-bin-param"/>, find the probability of
making <m>2</m> in <m>5</m> free throws if the probability of making one
is <m>0.86</m>?
</p>

<solution>
<p>
We need to calculate <me>
\begin{aligned}[t]
b(5-2; 5, 1-0.86) \amp = b(3; 5, 0.14)\\
\amp = {5\choose3}0.14^3(1-0.14)^{5-3}\\
\amp = 10(0.14)^3(0.86)^2\\
\amp \approx 0.020
\end{aligned}</me>.  This calculation corresponds to the ten
possible orderings of 2 makes in 5 shot attempts, the probabilities
associated with 2 'makes', and the probabilities associated with 3
'misses'.
</p>
</solution>
</statement>
</example>

<p>For certain calculations, it is helpful to use the theorem to reduce
the sizes of numbers used in the factorial or to find parameterizations
for which the probabilities are known by a table.</p>

<theorem xml:id="thm-bin-mean-var"> 
<title>Mean and variance of binomial distribution</title>

<statement>
<p>The mean and variance of a binomial random variable (or of the
binomial distribution) are <me>\mu = n\theta \text{ and } \sigma^2 =
n\theta(1-\theta)</me>.</p>
<proof><p>
These can be proved using the expectation and some clever re-indexing in
evaluating the sum. 
</p>
</proof>
</statement></theorem>

<theorem xml:id="thm-bin-successes"> 
<title>Proportion of binomial successes</title>
<statement>
<p>If <m>X</m> is a binomially-distributed random variable with
parameters <m>n</m>, <m>\theta</m>, and <m>Y = \dfrac{X}{n}</m> gives
the proportion of successes, 
<me>E[Y] = \theta \text{ and } \sigma_Y^2 =
\dfrac{\theta(1-\theta)}{n}</me>.</p>
</statement></theorem>

<exercise xml:id="exer-bin-dice">
<title>probabilities of dice rolls</title>
<statement>
<p> Find the expected value of the number of times a 2 or 3 shows in 15
rolls of a standard 6-sided die.
</p>
<hint>
What is the probability of 'success'?
</hint>
</statement>
</exercise>

<example xml:id="ex-bin-mgf"> 
<title>moment-generating function of a binomial distribution</title>

<statement>
<p>Find the moment-generating function of a binomial random variable
(or of the binomial distribution).</p>
</statement>

<statement>
<solution>
<p>Recall that <m>\displaystyle M_X(t) = E[e^{tx}] = \sum_x e^{tx} f(x;
\theta)</m>. 
This becomes <me>
\begin{aligned}[t]
M_X(t) \amp = \sum_{x=0}^n e^{tx} b(x; n, \theta)\\
\amp = \sum_{x=0}^n e^{tx} {n \choose x} \theta^x (1-\theta)^{n-x}\\
\amp = \sum_{x=0}^n {n \choose x} \left(\theta e^t\right)^x
(1-\theta)^{n-x}\\
\amp = \sum_{x=0}^n {n \choose x} (1-\theta)^{n-x}\left(\theta
e^t\right)^x\\
M_X(t) \amp = \left((1-\theta) + \theta e^t\right)^n
\end{aligned}</me>.
That last step, though a big leap in print, comes from applying the
binomial theorem in reverse, that is <me>\sum_{k=0}^n {n \choose
r}a^{n-r} b^r = (a+b)^n</me> where <m>a=1-\theta</m> and <m>b = \theta
e^t</m>.
</p>
</solution>
</statement></example>

<p>You might recognize this as <m>n</m> factors of the moment-generating
function of a Bernoulli random variable.</p>

<p> You could use the moment-generating function and <xref
ref="thm-4-9"/> to calculate moments about the origin used to find the
mean and
variance as a mechanism to prove <xref ref="thm-bin-mean-var"/>.
</p>

</subsection>
<exercises>

  <exercise>
 <title>Problem 5.7</title>
 <statement>
 <p> Verify <xref ref="thm-bin-successes"/>. 
  </p>
 </statement>
 </exercise>
 
 <exercise>
 <title>Problem 5.10</title>
 <statement>
 <p>If <m>X</m> is a binomial random variable, for what value of
<m>\theta</m> is the probability <m>b(x; n, \theta)</m> a maximum? In
other words, maximize <m>b(x; n, \theta)</m> with respect to
<m>\theta</m>.
 </p>
 </statement>
 </exercise> 

</exercises>


<!-- ....... .............. .............. ....... -->
<!-- ....... negbin-geom ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-discrete-negbin-geom">
<title>Negative Binomial and Geometric distributions</title>
<introduction>
<p>The binomial distribution describes the probability of a certain
number of successes in a certain amount of trials. Sometimes, instead,
we are
interested in the trial on which a particular success occurs.  This is
described by the negative binomial distribution.</p>

<p>This situation requires obtaining <m>k-1</m> successes across the
first <m>x-1</m> trials, with the <m>k^{\text{th}}</m> and final success
to occur on the <m>x^{\text{th}}</m> trial.</p>

<p>You will find tools for visualization at the following <url href="https://buddy.uco.edu/shiny/slaverty/mathstat/NegBin/"> link</url>.</p>

</introduction>


<definition xml:id="def-neg-bin">
<title>negative binomial distribution</title>

<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>negative binomial distribution</term> and is referred to as a
<term>negative binomial random variable</term> if and only if its
probability
distribution is given by <me>b^*(x; k, \theta) = {x-1\choose
k-1}\theta^k(1-\theta)^{x-k} \text{ for }x = k, k+1, \dots</me>.
</p>
</statement>
</definition>

<p> Sometimes we refer to the random variable as being distributed
according to <m>\operatorname{NegBin}(k, \theta)</m> or
<m>\operatorname{NB}(k, \theta)</m>.   The values of the random variable
describe <em> binomial waiting-times</em>, since the result is the
number of trials until arriving at a particular outcome of interest.
</p>

<theorem xml:id="thm-bin-negbin">
<title>negative binomial probability as a binomial probability</title>
<statement>
<p>
<me>b^*(x; k, \theta) = \frac{k}{x}b(k; x, \theta)</me>.
</p>
</statement>
<proof>
<p>
This can be shown, relatively quickly by relatively simple manipulation
of the definitions. Notice that we are equating on the left the negative
binomial and on the right the binomial.</p>
</proof>
</theorem>

<exercise xml:id="exer-negbin-bball">
<title>Free throws with the negative binomial</title>
<statement>
<p> A player makes a free throw with probability <m>0.86</m>. What is
the probability that the shooter makes her <m>3^{\text{rd}}</m> shot on
her <m>5^{\text{th}}</m> attempt?
</p>

<solution>
<p>
We need to calculate <me>b^*(5; 3, 0.86) = {5-1\choose3-1}0.86^3(1-0.86)^{5-3}
= 6(0.86)^3(0.14)^2</me>.  This means <m>2</m> shots were made in the
first <m>4</m> attempts, followed by the <m>3^{\text{rd}}</m> make on
the <m>5^{\text{th}}</m> attempt.
</p>
</solution>
</statement>
</exercise>

<theorem>
<title>Mean and variance of the negative binomial distribution</title>
<statement>
<p>
The mean and variance of the negative binomial distribution are <me>\mu
= \frac{k}{\theta}</me> and <me>\sigma^2 =
\frac{k}{\theta}\left(\frac{1}{\theta}-1\right)</me>.
</p>
</statement>
<!--><proof>
<p>
This can be shown, relatively quickly by relatively simple manipulation
of the definition.</p>
</proof>-->
</theorem>

<example xml:id="ex-negbin-mgf"> 
<title>moment generating function of the negative binomial distribution</title>
<statement>
<p>Find the moment-generating function of a negative binomial random
variable
(or of the negative binomial distribution).</p>
<solution>
<p>Recall that <m>\displaystyle M_X(t) = E[e^{tx}] = \sum_x e^{tx} f(x;
\theta)</m>. 
This becomes <me>
M_X(t) = \left(\dfrac{\theta e^t}{1-(1-\theta)e^t}\right)^k</me>.
</p>
</solution>
</statement></example>

<p> The question about when the first success occurs is a common one. 
So common, in fact, that it gets its own name, the <em>geometric
distribution</em>.  Now it should first be noted that we sometimes view
'success' strangely. Often we are instead thinking of a particular
'outcome of interest' rather than the traditional interpretation of
'success' as 'a good thing'.</p>


<definition xml:id="def-geom">
<title>geometric distribution</title>
<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>geometric distribution</term> and is referred to as a
<term>geometric random variable</term> if and only if its probability
distribution is given by <me>g(x; \theta) = \theta(1-\theta)^{x-1}
\text{ for }x = 1, 2, \dots</me>.
</p>
</statement>
</definition>

<p>The geometric distribution answers the age-old question "if at first
you don't succeed, how many times did you fail?"
</p>

<theorem>
<title>Mean and variance of the geometric distribution</title>
<statement>
<p>
The mean and variance of the geometric distribution are <me>\mu =
\frac{1}{\theta}</me> and <me>\sigma^2 =
\frac{1}{\theta}\left(\frac{1}{\theta}-1\right)</me>.
</p>
</statement>
</theorem>

<p> Sometimes we refer to the random variable as being distributed
according to <m>\operatorname{Geom}(\theta)</m>.
</p>


</subsection>
<exercises>
 <exercise>
 <title>Problem 5.18</title>
 <statement>
 <p> Prove <xref ref="thm-bin-negbin"/>.
 </p>
 </statement>
 </exercise>
 
 <exercise>
 <title>Problem 5.20</title>
 <statement>
 <p> Show that the moment-generating function of the geometric
distribution is given by <me>M_X(t) = \dfrac{\theta
e^t}{1-e^t(1-\theta)}</me>.
 </p>
 </statement>
 </exercise>
 
 <exercise>
 <title>Problem 5.21</title>
 <statement>
 <p> Use <xref ref="thm-4-9"/> and <me>M_X(t) = \dfrac{\theta
e^t}{1-e^t(1-\theta)}</me> to find <m>\mu</m> and <m>\sigma^2</m> by
differentiation.
 </p>
 </statement>
 </exercise>
 
 
</exercises>


<!-- ....... .............. .............. ....... -->
<!-- ....... hypergeom ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-discrete-hypergeom">
<title>Hypergeometric distribution</title>


<introduction>
<p> The Hypergeometric distribution describes the probabilities of
sampling from a finite population without replacement.  Unlike the
binomial where it is assumed that the probability of success is a
constant, with the hypergeometric distribution, the probability of
success changes with the selection process.</p>

<p>You will find tools for visualization at the following <url href="https://buddy.uco.edu/shiny/slaverty/mathstat/Hyper/"> link</url>.</p>

</introduction>


<definition xml:id="def-hyper">
<title>hypergeometric distribution</title>
<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>hypergeometric distribution</term> and is referred to as a
<term>hypergeometric random variable</term> if and only if its
probability
distribution is given by <me>h(x; n, N, M) = \dfrac{{M \choose x}{N-M
\choose{n-x}}}{{N \choose n}}
\text{ for }x = 1, 2, \dots, n; x \le M \text{ and } n-x \le N-M</me>.
</p>
</statement>
</definition>

<theorem>
<title>Mean and variance of the hypergeometric distribution</title>
<statement>
<p>
The mean and variance of the hypergeometric distribution are <me>\mu =
\frac{nM}{N}</me> and <me>\sigma^2 =
\frac{nM(N-M)(N-n)}{N^2(N-1)}</me>.
</p>
</statement>
</theorem>

<remark xml:id="typo-hyper">
<statement>
<p>There is a typo in the printed book for the class in the second
numerator term.</p>
</statement>
</remark>

<example xml:id="ex-hyper">
<title>hypergeometric distribution for truck inspections</title>
<statement>
<p>You randomly choose 6 out of 24 trucks for a new fleet of work
trucks.  It is known that 4 of the 24 trucks have failed a recent
emissions inspection. What is the probability that none of the trucks in
your fleet are "polluters"?</p>
<solution>
<p>Let <m>x = \text{# of polluters selected}</m>.  Then, we are looking
for <me>
h(0; 6, 24, 4) = \dfrac{{4 \choose 0}{24-4 \choose{6-0}}}{{24 \choose
6}}</me>.
Notice the denominator is the total number of ways that we can choose
<m>6</m> of <m>24</m> trucks.  The first term in the numerator is the
number of ways that we can choose <m>0</m> trucks from the collection of
<m>4</m> defective trucks.   The second term in the numerator is the
number of ways that we can choose <m>6-0</m> trucks from the <m>24-4</m>
non-defective trucks.
</p>
</solution>
</statement></example>


<remark xml:id="re-mean-var-hyper">
<statement>
<p> Below let <m>\theta = \dfrac{M}{N}</m> (think through this). The
mean and variance of the hypergeometric distribution can be written
<me>\mu =
\frac{nM}{N} = n\theta</me> and <me>\sigma^2 =
\frac{nM(N-M)(N-n)}{N^2(N-1)} =
n\theta(1-\theta)\left(\dfrac{N-n}{N-1}\right)</me>.
Above, the term <m>\left(\dfrac{N-n}{N-1}\right)</m> is called the
"finite population correction factor".
</p>
<p>
With this we might interpret the fraction <m>\theta = \dfrac{M}{N}</m>
as the "probability of success", given that we are choosing <m>M</m>
successes from <m>N</m> objects.
</p>
</statement>
</remark>

<p>As indicated at the beginning of this section, the binomial and
hypergeometric are related. The binomial describes a situation where
sampling is done with replacement, while the hypergeometric describes a
situation where sampling is done without replacement.</p>
</subsection>

<exercises>
 <exercise>
 <title>4.xx</title>
 <statement>
 <p>xx
 </p>
 </statement>
 </exercise>
 
</exercises>


<!-- ....... .............. .............. ....... -->
<!-- ....... poisson ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-discrete-poisson">
<title>Poisson distribution</title>

<introduction>
<p> The Poisson distribution describes the occurrence of events taking
place at a constant rate in time or over space.  For example, if car
accidents take place at a rate of 3 per 100 miles, we would use a
Poisson distribution to describe the probabilities of certain numbers of
accidents occurring along a known distance of highway.</p>

<p>You will find tools for visualization at the following <url href="https://buddy.uco.edu/shiny/slaverty/mathstat/Poisson/"> link</url>.</p>
</introduction>

<definition xml:id="def-poiss">
<title>Poisson distribution</title>
<statement>
<p>A discrete random variable <m>\displaystyle X</m> has a
<term>Poisson distribution</term> and is referred to as a
<term>Poisson random variable</term> if and only if its probability
distribution is given by <me>p(x; \lambda) = \dfrac{\lambda^x
e^{-\lambda}}{x!}</me>.
</p>
</statement>
</definition>

<theorem>
<title>Mean, variance, and MGF of the Poisson distribution</title>
<statement>
<p>
The mean and variance of the Poisson distribution are <me>\mu =
\lambda</me> and <me>\sigma^2 = \lambda</me>.
</p>
<p>
The moment-generating function of the Poisson distribution is <me>M_X(t)
= e^{\lambda(t-1)}</me></p>
</statement>
</theorem>

<p>Discuss connection of binomial and Poisson.</p>

<p>Discuss key applications.</p>
</subsection>
<exercises>
 <exercise>
 <title>4.xx</title>
 <statement>
 <p>xx
 </p>
 </statement>
 </exercise>
 
</exercises>

<!-- ....... .............. .............. ....... -->
<!-- ....... multivariate-discrete ....... -->
<!-- ....... .............. .............. ....... -->

<subsection xml:id="sub-discrete-multivariate">
<title>Multivariate distributions</title>
<p>See Sec. 5.8, 5.9</p> 

<introduction>
<p>The multinomial distribution is an extension of the binomial
distribution that tracks the occurrence in number of multiple types of
outcomes.</p>

<p>The multivariate hypergeometric distribution is an extension of the
hypergeometric distribution that tracks the occurrence in number of
multiple types of outcomes.</p>
</introduction>

</subsection> 
<exercises>
 <exercise>
 <title>4.xx</title>
 <statement>
 <p>xx
 </p>
 </statement>
 </exercise>
 
</exercises>

</section>

</chapter>
