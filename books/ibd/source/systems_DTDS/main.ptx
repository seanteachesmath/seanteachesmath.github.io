<chapter xml:id="higher-order-dtds">
<title>Discrete-time dynamical systems with linear algebra</title>

<section xml:id="discrete-time-with-linear-algebra">
<title>Discrete-time dynamical systems with linear algebra</title>

<introduction> We spent some time on the Nicholson-Bailey model for a few important
reasons: largely because it is a great example of the modeling process.
The results it generates may be bothersome. But the idea that we told a
rough story, then iteratively refined it is the art of mathematical
modeling. </introduction>

<p> Recall our example concerning weekly dandelion dynamics. Previously,
we counted only the number of flowering plants present in our
<sq>yard</sq> each week. We can count a bit more carefully, and take
advantage of more biological information if we think about the
’structure’ of the population. Ignoring seeds, in reality we have at
least a few ways to break down the plant community: </p>

<p> <ul> <li> <p>juveniles vs. adults </p> </li> <li> <p>seedlings vs.
vegetative vs. flowering vs. seed-setting </p> </li> <li>
<p>non-reproductive vs. reproductive </p> </li> </ul> </p>


<p> We will lump together the seedlings and vegetative plans as
<sq>non-reproductive</sq> and the flowering and seed-setting plants as
<sq>reproductive</sq>. Let <m>V_t</m> be the number of non-reproductive
(vegetative) plants in the yard and <m>R_t</m> be the number of
reproductive plants in the yard, both at week <m>t</m>. </p>


<p> We will use familiar notation for parameters. Since it is
challenging to count seeds after they have left the plant, and nobody
vacuums seeds from the yard, we’ll focus on the life stages above.</p>

<table>
<title></title> <tabular> <row class="odd"> <cell halign="left"><m>s</m></cell> <cell halign="left">be the number of
seedlings generated per plant</cell> </row> <row class="even"> <cell halign="left"><m>\sigma</m></cell> <cell halign="left">be the fraction
of seedlings that survive to adulthood</cell> </row> <row class="odd">
<cell halign="left"><m>a</m></cell> <cell halign="left">be the fraction
of adults that survive</cell> </row> </tabular> </table>


<p> This means we can write <me>\begin{aligned}
 
V_{t+1}&amp;=0\cdot V_t+s\cdot R_t\\ 
R_{t+1}&amp;=\sigma \cdot V_t+ a\cdot R_t.
\end{aligned}</me> This looks like a matrix equation,
<me>\left(

\begin{array}{c}
V_{t+1}\\
R_{t+1}\end{array}
\right) =
\left(

\begin{array}{cc}
0 &amp; s\\
\sigma &amp;a
\end{array}
\right)\left(

\begin{array}{c}V_{t}\\
R_{t}
\end{array}
\right).</me> With a single equation, it was
easy enough to determine growth. This is less obvious with a higher
dimensional model. Additionally, we might be interested in the following
questions: </p>


<p>
<ul>
<li> <p> Will the population grow? </p> </li> 
<li> <p> If it grows, how fast is it going to grow? </p> </li> 
<li> <p> What is the balance between reproductive and non-reproductive dandelions in the
population? </p> </li>
</ul>
</p>


<p> For a plant starting in the non-reproductive state (a one week old
plant), we track its lifetime reproduction in the following table: </p>


<table>
<title>Starting with a single female, she must survive to
adulthood (<m>\sigma</m>), then every time after survive another week as
an adult (a).</title> 
<tabular> <row header="yes"> <cell halign="left">Age (Weeks)</cell> 
<cell halign="left">Population</cell>
<cell halign="left">Fecundity</cell> </row> 
<row class="odd"> <cell halign="left">1</cell> <cell halign="left">1</cell> <cell halign="left">0</cell> </row> 
<row class="even"> <cell halign="left">2</cell> <cell halign="left"><m>\sigma</m></cell> <cell halign="left"><m>s</m></cell> </row> 
<row class="odd"> <cell halign="left">3</cell> <cell halign="left"><m>\sigma</m> <m>a</m></cell>
<cell halign="left"><m>s</m></cell> </row> 
<row class="even"> <cell halign="left">…</cell> <cell halign="left">…</cell> <cell halign="left">…</cell> </row> 
<row class="odd"> <cell halign="left">n</cell> <cell halign="left"><m>\sigma a ^{n-2}</m></cell>
<cell halign="left"><m>s</m></cell> </row> 
<row class="even"> <cell halign="left">…</cell> <cell halign="left">…</cell> <cell halign="left">…</cell> </row> </tabular> </table>


<p> Next we append a column for the reproductive value of each age
(remembering that our model only tracks two age classes, but once plants
flower they <em>could</em> survive indefinitely): </p>

<table>
<title>Starting with a single female, she must survive to
adulthood (<m>\sigma</m>), then every time after survive another week as
an adult (a).</title>
<tabular> <row header="yes"> <cell halign="left">Age (Weeks)</cell> <cell halign="left">Population</cell>
<cell halign="left">Fecundity</cell> <cell halign="left">Value</cell>
</row> <row class="odd"> <cell halign="left">1</cell> <cell halign="left">1</cell> <cell halign="left">0</cell> <cell halign="left">0</cell> </row> <row class="even"> <cell halign="left">2</cell> <cell halign="left"><m>\sigma</m></cell> <cell halign="left"><m>s</m></cell> <cell halign="left"><m>s\sigma</m></cell>
</row> <row class="odd"> <cell halign="left">3</cell> <cell halign="left"><m>\sigma a</m></cell> <cell halign="left"><m>s</m></cell>
<cell halign="left"><m>s\sigma</m> a</cell> </row> <row class="even">
<cell halign="left">…</cell> <cell halign="left">…</cell> <cell halign="left">…</cell> <cell halign="left">…</cell> </row> <row
class="odd"> <cell halign="left">n</cell> <cell halign="left"><m>\sigma
a ^{n-2}</m></cell> <cell halign="left"><m>s</m></cell> <cell halign="left"><m>s\sigma a^{n-2}</m></cell> </row> <row class="even">
<cell halign="left">…</cell> <cell halign="left">…</cell> <cell halign="left">…</cell> <cell halign="left">…</cell> </row> </tabular>
</table>


<p> Starting from seedling, the expected lifetime reproduction of a
plant is <me>ELR=s\sigma+s\sigma a + s\sigma a^2 + \dots .</me> By
definition <m>a</m> is a weekly survival probability for adult plants,
so <m>a\leq1</m>. Keep this in mind as we press on: <me>\begin{aligned}
ELR &amp; = s\sigma+s\sigma a + s\sigma a^2 + \dots \\ 
&amp; = s\sigma\left(1+a+a^2+\dots\right)\\
&amp; = s\sigma \sum_{k=0}^\infty a^k
\end{aligned}</me> Knowing what we do about geometric series, <me>ELR = s\sigma \sum_{k=0}^\infty a^k = s\sigma\left(\frac{1}{1-a}\right).</me> So, <m>ELR &gt;1</m> when
<m>s\sigma&gt;1-a</m>. This is identical to our <sq>adult
plant</sq>-only model result,<me>s\sigma+a&gt;1!</me> </p>


<paragraphs xml:id="questions">
<title>Questions</title> 
<p>
<ul>
<li><p> What’s so special about ELR as a measure of growth? </p> </li>
<li><p> How does ELR relate to eigenvalues? </p> </li> 
</ul>
</p>
</paragraphs>

<paragraphs xml:id="answers">
<title>Answers</title> <p> For a matrix
<m>A</m>, like our transition matrix above, a number <m>\lambda</m> is
an eigenvalue with eigenvector <m>x</m> if<me>Ax=\lambda x.</me> The
eigenvalue reduces the dimension in multidimensional problems. It turns
matrix multiplication into scalar multiplication. How do we find
eigenvalues? </p> </paragraphs>

<paragraphs xml:id="linear-algebra-review">
<title>Linear algebra review</title>


<p> We first want to write our eigenvalue problem as:<me>Ax-\lambda
x=0.</me> Then, since <m>\lambda</m> is a number, <me>(A-\lambda
I)x=0,</me> where <m>I</m> is the appropriate <sq>identity matrix</sq>.
</p>


<p> Let’s take <me>A= \left(

\begin{array}{cc}
a &amp; b\\
c &amp; d
\end{array}
\right),</me> so that <me>A-\lambda I=
\left(
\begin{array}{cc}
a-\lambda &amp; b\\
c &amp; d-\lambda
\end{array}
\right).</me> </p>


<p> Eigenvalues solve <me>\operatorname{det}(A-\lambda I)=0.</me>
<me>\begin{aligned}
0&amp;=\operatorname{det}(A-\lambda I)\\
&amp;=(a-\lambda)(d-\lambda)-bc\\
0&amp;=\lambda^2-(a+d)\lambda+ad-bc
\end{aligned}</me> </p>


<p> Solutions are<me>\lambda_{\pm}=\frac{(a+d)\pm\sqrt{(a+
d)^2-4(ad-bc)}}{2}.</me> From here it helps to consider specific
examples so we do not have to solve equations containing obtuse
algebraic expressions. </p>

</paragraphs>


<subsection xml:id="linear-discrete-time-models-2d-1">
<title>Linear discrete-time models (2D)</title>

<paragraphs xml:id="question">
<title>Question</title>


<p> How do structured and unstructured populations differ? From a one
dimensional model ignoring plant developmental stage,<me>N_t=r N_t,</me>
where <m>r=s\sigma+a</m>, we wrote a two-dimensional
model,<me>P_{t+1}=MP_t,</me> where <m>P_0=(V_0, R_0)^T</m> and
<me>M=\left(
\begin{array}{cc}0 &amp; s\\\sigma &amp;
a\end{array}\right).</me> </p>


<p> Keeping with our example, eigenvalues of <m>M</m> are found using
<me>\det\left(
\begin{array}{cc}
-\lambda &amp; s\\
\sigma &amp;
a-\lambda
\end{array}
\right)=0.</me> This gives <me>\begin{aligned}
0&amp;=-\lambda(a-\lambda)-s\sigma\\
&amp;=\lambda^2-a\lambda-s\sigma
\end{aligned}</me> Using the quadratic
formula,<me>\lambda_\pm = \frac{a\pm\sqrt{a^2+4s\sigma}}{2}.</me> </p>


<p> Suppose we know the initial plant distribution,
<me>P_0=\left(
\begin{array}{c}
V_0\\
R_0
\end{array}
\right),</me>
the solution to our model is <me>P_t=M^tP_0.</me> First write,
<m>P_0=c_1 v_1+c_2 v_2</m>, where <m>c_1, c_2</m> are constants and
<m>v_1, v_2</m> are eigenvectors. We are assuming that <m>v_1, v_2</m>
are linearly independent, thus they form a basis in two-dimensions, such
that any other vector can be written as a linear combination.
<me>\begin{aligned}
P_1&amp;=A P_0 &amp; \quad\text{(start)}\\
&amp; = A(c_1 v_1+c_2 v_2)&amp; \quad\text{(basis vectors)}\\
&amp; = c_1 Av_1+c_2 Av_2&amp; \quad\text{(distributive property)}\\
P_1&amp; = c_1 \lambda_1 v_1+c_2 \lambda_2v_2&amp; \quad\text{(eigenvalues!)}
\end{aligned}</me> We can compute <m>P_2</m>,
<me>\begin{aligned}
 P_2&amp;=A P_1\\
 &amp; = A(c_1 \lambda_1 v_1+c_2 \lambda_2 v_2)\\
 &amp; = (c_1 \lambda_1) Av_1+(c_2\lambda_2) Av_2\\
 &amp; = c_1 \lambda_1^2 v_1+c_2 \lambda_2^2v_2
 \end{aligned}</me> And
similarly, <me>P_t=c_1\lambda_1^tv_1+c_2\lambda_2^tv_2.</me> If we
assume that <m>|\lambda_1|&gt;|\lambda_2|</m>, then <me>P_t\approx c_1
\lambda_1^t v_1.</me> We will see how this approximation works at the
end of the following example. But, perhaps motivated by this
approximation, we see that the magnitude of <m>\lambda_1</m> is
important to the growth of the population, both <m>V_t</m> and
<m>R_t</m>. The population changes by a factor <m>\lambda_1</m> each
generation. It grows if <m>\lambda_1&gt;1</m> and shrinks if
<m>\lambda_1&lt;1</m>. </p>


<p> Let <m>\lambda_1</m> be the positive eigenvalue,
<m>\lambda_1&gt;1</m>, <me>\begin{aligned}
 \lambda_1 =\frac{a+\sqrt{a^2+4s\sigma}}{2}&amp;&gt;1\\
a+\sqrt{a^2+4s\sigma}&amp;&gt;2\\
 \sqrt{a^2+4s\sigma}&amp;&gt;2-a\\
a^2+4s\sigma&amp;&gt;(2-a)^2\\ 
a^2+4s\sigma&amp;&gt;4-4a+a^2\\
4s\sigma&amp;&gt;4-4a\\ 
s\sigma&amp;&gt;1-a\\
s\sigma+a&amp;&gt;1
\end{aligned}</me> The positive eigenvalue
<m>\lambda_1&gt;1</m> if <m>r=s\sigma+a&gt;1</m>, but in general,
<m>ELR\neq\lambda_1</m>! But, if <m>\lambda_1&gt;1</m> so is <m>ELR</m>,
and vice versa. Again, our characteristic polynomial, that governs the
eigenvalues is<me>C(\lambda)=\lambda^2-a\lambda-s\sigma.</me> Since
<m>s, \sigma&gt;0</m>, we have <m>C(0)&lt;0</m> and we know that
<m>C(\lambda)</m> is concave up. If <m>C(1)&lt;0</m>, we know that the
leading eigenvalue <m>\lambda&gt;1</m>. Lastly, let’s study the
relationships between <m>1, \lambda_+</m>, and <m>r</m>. We’ve already
looked at some of the relationships involving <m>1</m>. Now,
<m>\lambda&lt;r=s\sigma+a</m> when <me>\begin{aligned}
 0&amp;&lt;C(r)\\
0&amp;&lt;r^2-ar-s\sigma\\ 
s\sigma&amp;&lt;r(r-a)\\
s\sigma&amp;&lt;(s\sigma+a)(s\sigma+a-a)\\
s\sigma&amp;&lt;s\sigma(s\sigma+a)\\
0&amp;&lt;s\sigma(s\sigma+a)-s\sigma\\
0&amp;&lt;s\sigma(s\sigma+a-1)
\end{aligned}</me> This is satisfied when
<m>r=s\sigma+a&gt;1</m>, thus <m>1&lt;\lambda&lt;ELR</m>. For the
reverse, <m>ELR&lt;\lambda&lt;1</m> when <m>r=s\sigma+a&lt;1</m>. We
will also look at the relationships between <m>r</m>, <m>ELR</m>, and
<m>\lambda</m> in the example, so that we can actually compute
eigenpair. </p> </paragraphs>

<example xml:id="example-matrix-model">
<title>A matrix model</title>
<p> Recall <m>r=s\sigma+a</m> was the per generation growth rate from
the one-equation model. In that model, we made no distinction between
plant growth stages, an assumed that all plants were capable of
reproducing. When we considered the reproductive schedule of our plants,
we derived <m>ELR</m> as a measure of the replacement rate of each
individual plant. Let <m>a=\frac{2}{3}</m>, <m>s=\frac{16}{9}</m>,
<m>\sigma=\frac{1}{2}</m>, so that,
<m>r=\left(\frac{16}{9}\right)\left(\frac{1}{2}\right)+
\left(\frac{2}{3}\right)=
\left(\frac{14}{9}\right)\approx1.\overline{55}</m>. Also,
<m>ELR=\frac{\left(\frac{16}{9}\right)\left(\frac{1}{2}\right)}{\frac{1}{3}}=\frac{8}{3}\approx2.\overline{66}</m>. 
When vegetative plants are less likely to
mature (small <m>\sigma</m>, <xref ref="fig-elr-eig" />) weekly
adult survivorship, <m>a</m>, must increase in order for population
growth to occur (<m>r, ELR, \lambda&gt;1</m>). </p>

<figure xml:id="fig-elr-eig"> 
<image source="elr_vs_eig_a.png" width="50%"/>
<caption>Relationships between <m>r</m>,
<m>ELR</m>, and <m>\lambda</m>, for fixed <m>s=\frac{16}{9}</m> and
(left) <m>\sigma=\frac{1}{2}</m> or (right) <m>\sigma=\frac{1}{3}</m>,
over a range of adult weekly survival probabilities, <m>0\leq a\leq
1</m>.</caption> </figure>

<figure xml:id="fig-elr-eig2"> 
<image source="./images/elr_vs_eig_b.png" width="50%"/>
<caption>Relationships between <m>r</m>, <m>ELR</m>, and <m>\lambda</m>,
for fixed <m>s=\frac{16}{9}</m> and (left) <m>\sigma=\frac{1}{2}</m> or
(right) <m>\sigma=\frac{1}{3}</m>, over a range of adult weekly survival
probabilities, <m>0\leq a\leq 1</m>.</caption> </figure> </example>

<paragraphs xml:id="question-1">
<title>Question</title>


<p> What is the effect of population structure (tracking flower types),
in growing and shrinking flower populations (see <xref
ref="fig-elr-eig" />)? </p>

</paragraphs>

<paragraphs xml:id="answer">
<title>Answer</title>

<p> Imposing structure reduces the growth rate (relative to <m>r</m>) in
growing populations. Imposing structure slows the decay rate (relative
to <m>r</m>) in shrinking populations. In this parameterization,
<me>\begin{aligned}
\lambda_\pm &amp;=\frac{\frac{2}{3}\pm\sqrt{\frac{4}{9}+4\left(\frac{16}{9}\right)\left(\frac{1}{2}\right) }}{2}\\
&amp;=\frac{1}{3}\pm\frac{1}{2}\sqrt{\frac{4 }{9}+\frac{32}{9}}\\
&amp;=\frac{1}{3}\pm 1\\
\lambda_\pm&amp;=\frac{4}{3}, -\frac{2}{3}.
\end{aligned}</me> <me>\left(
\begin{array}{cc}
0 &amp;\frac{16}{9}\\[2pt]
\frac{1}{2} &amp;\frac{2}{3}
\end{array}\right)
\left(
\begin{array}{c}
x_1\\
x_2
\end{array}
\right)=
\frac{4}{3}\left(
\begin{array}{c}
x_1\\
x_2
\end{array}
\right).</me> Notice that <m>ELR&gt;\lambda_+&gt;1</m>,
so that the population grows. </p>

<figure xml:id="fig-SAD"> 
<image source="./images/SAD.png" width="50%"/>
<caption>Left) Weekly temporal
dynamics of vegetative and reproductive plants. Right) Stable age
distribution and iterated solutions starting from <m>(V_0,
R_0)=(0,1)</m>. Initial condition is black dot.</caption> </figure>


<p> The eigenvector associated with <m>\lambda=\frac{4}{3}</m> is of the
form<me>v_1=\left(
\begin{array}{c}x_1\\
\frac{3}{4}x_1\end{array}\right).</me> The eigenvector associated
with <m>\lambda=-\frac{2}{3}</m> is of the
form<me>v_1=\left(
\begin{array}{c}x_1\\
-\frac{3}{8}x_1\end{array}\right).</me> </p> </paragraphs>

<paragraphs xml:id="question-2">
<title>Question</title>


<p> How do the eigenvectors help explain long term population growth
(see <xref ref="fig-SAD" />)? </p> </paragraphs>

<paragraphs xml:id="answer-1">
<title>Answer</title>


<p> Long-term proportions approach the distribution described by the
leading eigenvector. Numbers increase geometrically. Start with a
typical initial condition <m>P_0=(V_0, R_0)=(0,1)</m>. We first want to
express <m>P_0</m> as a linear combination of
eigenvectors.<me>\left(
\begin{array}{c}
0 \\
1
\end{array}
\right) =
c_1\left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}
\right)+c_2\left(
\begin{array}{c}
1\\
-\frac{3}{8}
\end{array}
\right).</me> Skipping a few
calculations, <m>c_1=-c_2</m> and <m>c_1=\frac{8}{9}</m>. Finally we can
write, <me>\begin{aligned}
P_1&amp;=A P_0\\ 
&amp; = A\left(c_1\left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}
\right)+c_2
\left(
\begin{array}{c}
1\\
-\frac{3}{8}
\end{array}
\right)\right)\\
&amp; = c_1 A\left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}\right)+c_2 A\left(
\begin{array}{c}
1\\
-\frac{3}{8}
\end{array}
\right)\\
P_1&amp; = c_1 \lambda_1^2 \left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}\right)+c_2 \lambda_2^2\left(
\begin{array}{c}
1\\
-\frac{3}{8}
\end{array}\right)\\
 P_1&amp; = \left(
 \frac{8}{9}\right)
\left(\frac{4}{3}\right)^2 \left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}\right)- \left(\frac{8}{9}\right)
\left(\frac{2}{3}\right)^2\left(
\begin{array}{c}
1\\
-\frac{3}{8}
\end{array}\right),
\end{aligned} </me>
as before. Iterating this solution we wind up with,
<me>P_t=\frac{8}{9}\left(\frac{4}{3}\right)^t\left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}
\right)-
\frac{8}{9}\left(\frac{2}{3}\right)^t\left(
\begin{array}{c}
1\\
-\frac{3}{8}
\end{array}
\right)</me> Since the second term contains a
value <m>\lambda_2&lt;1</m> which is raised to a larger and larger
power, its contribution decreases. If we ignore it (at large <m>t</m>),
<me>P_t\approx\frac{8}{9}\left(\frac{4}{3}\right)^t\left(
\begin{array}{c}
1\\
\frac{3}{4}
\end{array}
\right).</me> </p>


<p> The population will grow 33% larger each generation, but the
proportion of young (non-reproductive) and old (reproductive) plants
will remain fixed. This suggests that juvenile (tasty young plants) will
outnumber the older flowering plants, specifically, the flowering plants
will be 75% the abundance of young plants. Alternatively, young plants
will be 33% more abundant than old plants. It might also be useful to
use our leading eigenvector approximation, rather than our exact matrix
solution. We plot the approximate dynamics of each plant type, as well
as the comparison of the exact and approximate solutions in <xref
ref="fig-exac-app" /> </p>

<figure xml:id="fig-exac-app"> 
<image source="./images/exact_vs_approx.png" width="50%"/>
<caption>Left)
Approximate dynamics using first eigenpair. Right) Iterated solutions
starting from <m>(V_0, R_0)=(0,1)</m> for matrix solutions (open
circles) and approximate solutions (closed circles).</caption> </figure>
</paragraphs>

</subsection>


</section>

<!-->
<section xml:id="nonlinear-discrete-time-models-2d">
<title>Nonlinear discrete-time models (2D)</title>



<paragraphs xml:id="motivation-the-discrete-logistic">
<title>Motivation: the discrete logistic</title>


<p> The discrete logistic model is <me>Y_{t+1}=r(1-Y_t)Y_t,</me> where
<m>Y_t</m> between <m>[0,1]</m> is the <sq>scaled density</sq> of hosts,
and <m>p.c.p.=r(1-Y_t).</m> Expanding the model we can write,
<me>Y_{t+1}=rY_t-(rY_t)Y_t.</me> Reading the model in this form, we can
think of constant per capita births <m>r</m> but it looks like the per
capita mortality is of the form <m>rY_t</m>. One interpretation of this
is, </p>


<p><ul> <li> <p> births are independent of population density </p> </li>
<li> <p> death increases with population density </p> </li>

</ul></p>


<p> What if instead of your own species controlling your mortality
(assuming you are a <m>Y_t</m>) a second species, <m>Z_t</m>, is
responsible for your mortality. We’ll assume that it benefits from
eating you, but would otherwise die out, its a specialist. We will
assume that it is either better or worse at eating you than you are at
eating/killing yourself, so that your per capita mortality as a function
of the density of <m>Z_t</m> is <m>pZ_t</m>. We can rewrite
<sq>your</sq> equation as, <me>Y_{t+1}=rY_t-(pZ_t)Y_t.</me> </p>


<p> We’ll assume that a <m>Z_t</m> turns some fraction <m>\epsilon</m>
of consumed <m>Y_t</m>’s into new <m>Z_t</m> (i.e., growth of <m>Z_t</m>
depends directly on the amount of <m>Y_t</m> consumed). But again, in
the absence of food <m>Z_t</m> will die. The equation for <m>Z_t</m>
looks like, <me>Z_{t+1}=\epsilon(pY_t)Z_t-mZ_t.</me> Putting these
together, we have our first 2D nonlinear system, <me>\begin{aligned}
Y_{t+1}&amp;=rY_t-pZ_tY_t\\ Z_{t+1}&amp;=\epsilon pY_tZ_t+mZ_t,
\quad\text{this should be a +m not a -m!}
\end{aligned}</me> </p>


<p> Notice that we could define <m>g=\epsilon p</m> if we wanted to
simplify (the appearance) of the first term in <m>Z_{t+1}</m>.
<me>\begin{aligned}
 Y_{t+1}&amp;=rY_t-pZ_tY_t\\ Z_{t+1}&amp;=
gY_tZ_t+mZ_t, \quad\text{this should be a +m not a
-m}!
\end{aligned}</me> </p> </paragraphs>


<paragraphs xml:id="an-approach-to-nonlinear-multi-species-dynamics">
<title>An approach to nonlinear, multi-species dynamics.</title> <p> To
study this model we could, <ul> <li> <p> Iterate solutions numerically</p> </li> <li> <p> Attempt to <sq>solve it</sq> </p> </li> </ul> </p>

<p> To iterate our model, we would have to have parameter values and a
suitable initial condition. We might not have a clue what these values
are so we will ignore that approach and try to <sq>solve it.</sq>
Solving such a model typically means, </p> <p><ul> <li> <p> compute
equilibria </p> </li>

<li> <p> compute linearization </p> </li>

<li> <p> analyze stability </p> </li> </ul></p> <p> As before,
equilibria requires <m>Y_{t+1}=Y_t=Y^*</m> and simultaneously
<m>Z_{t+1}=Z_t=Z^*</m>. <me>\begin{aligned}
 Y^*&amp;=rY^* -pZ^*Y^*\\
Z^*&amp;= gY^*Z^*+mZ^*, \quad\text{this should be a +m not a
-m!}
\end{aligned}</me> </p> <p> To satisfy the first, either
<m>Y^*=0</m> or <m>1=r-pZ^*</m>, the second of which implies,
<me>Z^*=\frac{r-1}{p}.</me> To satisfy the second, either <m>Z^*=0</m>
or <m>1=gY^*+m,</m> the second of which implies,
<me>Y^*=\frac{1-m}{g}.</me> Thus our equilibria are <m>(Y^*, Z^*)=(0,
0)</m> or <m>(Y^*, Z^*)=(\frac{1-m}{g}, \frac{r-1}{p})</m>. </p> <p> We
have to figure out how to determine stability at each equilibrium point
to know whether or not species persist or go extinct. We might think
that linear matrix theory, determinants, and eigenvalues would be of use
here. Our first step is to form a linear approximation to our nonlinear
dynamics near equilibria. To do so, we compute the Jacobian matrix, a
matrix of partial derivatives. </p> <p> We notice that our model can be
written as a set of two updating functions each depending on two
variables, <me>\begin{aligned}
Y_{t+1}&amp;=F(Y_t, Z_t)=rY_t-pZ_tY_t\\
Z_{t+1}&amp;= G(Y_t, Z_t)=gY_tZ_t+mZ_t, \quad\text{this should be a +m not a -m!}
\end{aligned}</me> Now, the motivation and methodology are
the same as with 1D models, we are interested in thinking about
<m>Y_t=Y^*+y_t</m> and <m>Z_t=Z^*+z_t</m>, which means each solution
(e.g., <m>Y_t</m>) is a combination of equilibrium value (e.g.,
<m>Y^*</m>) and some small perturbation (e.g., <m>y_t</m>). The Jacobian
is a matrix of partial derivatives of our updating functions with
respect to the state variables. We could derive this as we did with a
Taylor series expansion of a 1D model. </p> <p> Then, skipping some
steps, we can compute the Jacobian as follows (we will drop the
subscripts for simplicity), <me>J(Y, Z)=\left(

\begin{array}{cc}
\frac{\partial^{} {F}}{\partial {Y}^{}} &amp; \frac{\partial^{}{F}}{\partial {Z}^{}}\\[8pt]
\frac{\partial^{} {G}}{\partial {Y}^{}}&amp; \frac{\partial^{} {G}}{\partial {Z}^{}} 
\end{array}\right).</me>
</p> <p> Our work is not done, just yet. Since we are concerned with the
dynamics <sq>near equilibrium</sq> we have to evaluate the Jacobian at
the equilibrium. An example, in just a minute, should make this clear.
<me>\left(

\begin{array}{cc}
y_{t_1}\\[8pt]
z_{t+1}\end{array}
\right)=\left.\left(

\begin{array}{cc}
\frac{\partial^{} {F}}{\partial {Y}^{}} &amp; \frac{\partial^{} {F}}{\partial {Z}^{}}\\[8pt] \frac{\partial^{} {G}}{\partial {Y}^{}} &amp;
\frac{\partial^{} {G}}{\partial {Z}^{}} \end{array}\right)\right|_{(Y^*,Z^*)}\times\left(

\begin{array}{cc} 
y_{t}\\[8pt] 
z_{t}
\end{array}\right).</me> </p> </paragraphs>



<example xml:id="example-2">
<title>Example</title>


<p> Continuing with our current model, we will compute the Jacobian.
<me>
\end{aligned} \frac{\partial^{} {F}}{\partial {Y}^{}} &amp;=
\frac{\partial^{} {}}{\partial {Y}^{}}\left(rY-pZY\right)= r-pZ\\
\frac{\partial^{} {F}}{\partial {Z}^{}} &amp;= \frac{\partial^{}
{}}{\partial {Z}^{}}\left(rY-pZY\right)= -pY\\ \frac{\partial^{}
{G}}{\partial {Y}^{}} &amp;= \frac{\partial^{} {}}{\partial
{Y}^{}}\left(gYZ-mZ\right)= gZ\\ \frac{\partial^{} {G}}{\partial {Z}^{}}
&amp;= \frac{\partial^{} {}}{\partial {Z}^{}}\left(gYZ-mZ\right)= gY+m,
\quad\text{this should be a +m not a -m}.
\end{aligned}</me> </p>


<p> So,<me>J(Y,Z)=\left(
\begin{array}{cc} r-pZ\ &amp; -pY\\[8pt] gZ
&amp; gY+m \end{array}\right), \quad\text{this should be a +m not a
-m}.</me> </p>


<p> So at the <sq>zero</sq> equilibrium,
<me>J(0,0)=\left(
\begin{array}{cc} r\ &amp; 0\\[8pt] 0 &amp; m
\end{array}\right), \quad\text{this should be a +m not a -m}..</me>
</p>


<p> So at the nontrivial equilibrium,
<me>J^*=J(Y^*,Z^*)=\left(
\begin{array}{cc}
r-p\left(\frac{r-1}{p}\right)\ &amp; -p\left(\frac{1-m}{g}\right)\\[8pt]
g\left(\frac{r-1}{p}\right) &amp; g\left(\frac{1-m}{g}\right)+m
\end{array}\right)= \left(
\begin{array}{cc} 1 &amp;
-p\left(\frac{1-m}{g}\right)\\[8pt] g\left(\frac{r-1}{p}\right) &amp; 1
\end{array}\right).</me> </p>


<p> Rather than compute and study the eigenvalues directly, we’ll take
the scenic route to our solution. We will compute a few key properties
of the matrix to understand the behavior of eigenvalues: trace,
determinant, and discriminant. The trace of <m>J^*</m>,
<me>\tau(J^*)=\operatorname{Tr}(J^*),</me> is the sum of its diagonal
entries, and in this case the diagonal sums to <m>\tau=2</m>. The
determinant of <m>J^*</m> is,
<me>\Delta(J^*)=\operatorname{det}(J^*)=1+(1 -m)(r-1).</me> The
discriminant of <m>J^*</m>, is
<m>\operatorname{Disc}(J^*)=\tau^2-4\Delta</m>, and
<me>\operatorname{Disc}(J^*)=-4(1-m)(r-1).</me> Eigenvalues are given
by, <me>\lambda_\pm=\frac{\tau\pm\sqrt{\tau^2-4\Delta}}{2},</me> and
they are real if <m>\operatorname{Disc}(J^*)=\tau^2-4\Delta&gt;0</m> and
imaginary otherwise. One thing is certain, we need
<me>-1&lt;\frac{\tau}{2}&lt;1.</me> This is because we want the roots to
be between <m>(-1,1)</m>. If we want <em>roots</em> in this interval,
the vertex of the parabola better be there too. We’ll use the location
of the vertex and <em>distance</em> to the roots to compute some
stability criterion and build a stability diagram, next time. </p>

<table>
<title></title> <\begin{aligned}
> <row header="yes"> <cell halign="center">Equilibrium</cell> <cell halign="center"><m>\tau=\operatorname{Tr}(J^ *)</m></cell> <cell halign="center"><m>\Delta=\operatorname{det} (J^*)</m></cell> <cell halign="center"><m>\operatorname{Disc}(J^*)= \tau^2-4\Delta</m></cell>
<cell halign="center"><m>\lambda_i</m></cell> </row> <row class="odd">
<cell halign="center"><m>(0, 0)</m></cell> <cell halign="center"><m>r+m</m></cell> <cell halign="center"><m>rm</m></cell>
<cell halign="center"><m>(r-m)^2</m></cell> <cell halign="center">Real</cell> </row> <row class="even"> <cell halign="center"><m>(Y^*, Z^*)</m></cell> <cell halign="center"><m>2</m></cell> <cell halign="center"><m>1+(1-m)(r-1)</m></cell> <cell halign="center"><m>-4(1-m)(r-1)</m></cell> <cell halign="center">Complex
(if <m>r&gt;1</m>)</cell> </row> </tabular> </table>


<p> We will briefly see why this is a worrisome model, and move on to
more biologically interesting models. The trivial equilibrium <m>(0,
0)</m> will be stable for stupidly small values of <m>r, m</m>. The
nontrivial equilibrium is unstable and oscillatory, meaning that
practically a species will crash into the number zero and go extinct.
</p> </example>



<subsection
xml:id="nonlinear-discrete-time-models-2d-stability-criterion">
<title>Nonlinear discrete-time models (2D): Stability criterion</title>

<paragraphs xml:id="stability">
<title>Stability</title>


<p> Consider the Jacobian matrix <m>J^*</m> from the linearization of a
2D model. For <me>J^*=\left(
\begin{array}{cc}a &amp; b\\c&amp;
d\end{array}\right),</me> the associated characteristic polynomial is
<me>C(\lambda)=\lambda^2-\tau \lambda+\Delta,</me> where <m>\tau</m> is
the trace and <m>\Delta</m> is the determinant. Solving this with the
quadratic formula, <me>\lambda_\pm=\frac{\tau\pm\sqrt{\tau^2-4\Delta}}{
2}.</me> </p>

<p> We’ll take a graphical approach to understanding the behavior of
roots. First, notice that the vertex of the parabola is at
<m>\frac{\tau}{2},</m> since the roots are symmetric about the vertex.
We’ll assume the eigenvalues are distinct and that
<m>\lambda_+&gt;\lambda_-</m>. </p>


<p> For the leading eigenvalue, <m>\lambda_+&lt;1</m>, we need
<me>\begin{aligned}
 \lambda_+=\frac{\tau}{2}+\frac{\sqrt{\tau^2-4\Delta}
}{2}&amp;&lt;1\\ \frac{\sqrt{\tau^2-4\Delta}}{2}&amp;&lt;1-\frac{\tau
}{2}\\ \frac{\tau^2-4\Delta}{4}&amp;&lt;\left(1-\frac{\tau}
{2}\right)^2\\ \frac{\tau^2}{4}-\Delta&amp;&lt;1-\tau+\frac{\tau^2}
{4}\\ -\Delta&amp;&lt;1-\tau\Rightarrow
-1+\tau&lt;\Delta
\end{aligned}</me> If the determinant satisfies
<me>-1+\tau&lt;\Delta,</me> then <m>\lambda_+&lt;1</m>. </p>


<p> For the other eigenvalue, <m>\lambda_-&gt;-1</m>, we need
<me>\begin{aligned}
 \lambda_-=\frac{\tau}{2}-\frac{\sqrt{\tau^2-4\Delta}
}{2}&amp;&gt;-1\\ 1+\frac{\tau}{2} &amp; &gt;
\frac{\sqrt{\tau^2-4\Delta}}{2}\\ \left(1+\frac{\tau}{2}\right)^2 &amp;
&gt; \frac{\tau^2-4\Delta}{4}\\ 1+\tau+\frac{\tau^2}{4} &amp; &gt;
\frac{\tau^2}{4}-\Delta\\ 1+\tau&amp; &gt; -\Delta\Rightarrow
-1-\tau&lt;\Delta
\end{aligned}</me> If the determinant satisfies
<me>-1-\tau&lt;\Delta,</me> then <m>\lambda_-&gt;-1</m>. </p>


<p> We need both eigenvalue conditions satisfied simultaneously, so that
<me>\Delta&gt;|\tau|-1.</me> The second line from each calculation is
easily visualized in the following picture, roughly, the distance from
the vertex to the root, <me>\frac{\sqrt{\tau^2-4\Delta}}{2}</me> is less
than the distance from the vertex to the enclosing endpoint (see <xref ref="fig-roots" />). </p>

<figure xml:id="fig-roots">
<image source="./images/char_poly.png" width="50%"/>
<caption>Roots of the
characteristic polynomial.</caption> </figure>


<p> Lastly, we need complex roots which arise when
<m>\tau^2-4\Delta&lt;0</m>, to satisfy <m>|\lambda_i|&lt;1</m>. <me>
\begin{aligned}
\lambda_\pm&amp;=\frac{\tau}{2}\pm\frac{\sqrt{\tau^2-4\Delta}}{2}\\
&amp;=\frac{\tau}{2}\pm i \frac{\sqrt{4\Delta-\tau^2}}{2}\\
|\lambda_\pm|&amp;=\frac{\tau^2}{4}+ \Delta-\frac{\tau^2}{4}\\
|\lambda_\pm|&amp;=\Delta\Rightarrow \Delta&lt;1
\end{aligned}</me>
</p> </paragraphs>

<paragraphs xml:id="stability-triangle">
<title>Stability
triangle</title> <p> We need </p> <p><ul> <li> <p> <m>\operatorname{det}(J^*)&lt;1</m> </p> </li>

<li> <p> <m>\operatorname{det}(J^*) &gt; -1+|
\operatorname{Tr}(J^*)|</m> </p> </li>

<li> <p> Under
<m>\operatorname{det}(J^*)=\frac{\operatorname{Tr}(J^*)^2}{4}</m
>eigenvalues are real. </p> </li>
</ul></p>
<figure xml:id="fig-roots">
<image source="./images/discrete_stab.png" width="50%"/>
<caption>Roots of
the characteristic polynomial. <m>\tau</m> lies along the horizontal
axis and <m>\Delta</m> along the vertical axis.</caption> </figure>

</paragraphs>


</subsection>





<subsection xml:id="nicholson-bailey-and-on-to-continuous-tim">
<title>Nicholson-Bailey and on to continuous time</title>

<paragraphs xml:id="nicholson-bailey">
<title>Nicholson-Bailey</title>


<p> Stability of 2D, nonlinear, discrete-time models is summarized in <xref ref="fig-stab" />, using properties (matrix trace,
determinant, and discriminant) of the Jacobian matrix evaluated at
equilibrium. An equilibrium is stable only when its trace and
determinant map to regions within the triangle. Transient dynamics are
governed by the sign of the discriminant, when the discriminant is
negative, eigenvalue are complex and trajectories are oscillatory.
Otherwise, eigenvalues are real and non-oscillatory. </p>


<p> Why do we want <sq>small</sq> eigenvalues? We want small eigenvalues
because we have linearized the system near an equilibrium point. We want
perturbations to decay so that our solution returns (in some way,
oscillatory or not) to equilibrium. Thus, we want the <m>(0,0)</m>
equilibrium of our perturbed coordinate system to be stable. If we write
for some 2D nonlinear system <m>(X_t, Y_t)=(X^*+\hat x_t, Y^*+\hat
y_t)</m>, where <m>\hat x_t</m> and <m>\hat y_t</m> are our
perturbations, we want both <m>\hat x_t, \hat y_t\rightarrow0</m> so
that <m>(X_t, Y_t)\rightarrow(X^*, Y^*)</m>. We keep using the phrase
<sq>want</sq> because biologically
<m>(X_t\rightarrow0,Y_t\rightarrow0)</m> and <m>(X_t\rightarrow\infty,
Y_t\rightarrow\infty)</m> are often uninteresting outcomes. </p>

<figure xml:id="fig-stab">
<image source="./images/discrete_stability.png" width="50%"/>
<caption>Eigenvalues
are real in the hatched region and the equilibrium is stable.
Eigenvalues are complex in the solid region and the equilibrium is
stable, but approach to equilibrium is via damped oscillations. Outside
these regions, corresponding equilibria are unstable. Above the
parabola, solutions oscillation away from equilibria. <m>\tau</m> lies
along the horizontal axis and <m>\Delta</m> along the vertical
axis.</caption> </figure>

</paragraphs>

<example xml:id="example-nicholson-bailey">
<title>Nicholson-Bailey
model</title>


<p> We built our first 2D model from a poor starting point, the discrete
logistic model. We learned, intentionally and accidentally, that
multiplying by negative numbers is a bad idea. We hope to develop models
where the right hand sides can become small, but remain positive. </p>


<p> We will quickly look at the classic Nicholson-Bailey model. The
model assumes that caterpillars are an engine for turning out
parasitoids, each infected caterpillar produces a fixed amount of
parasitoid larvae. The model of invertebrate host-parasitoid dynamics is
of the form, <me>\begin{aligned}
 H_{t+1}&amp;= (\text{host
fecundity})\times(\text{host fraction surviving
parasitism})\times(\text{host population size})\\ P_{t+1}&amp;=
(\text{parasitoid production per host})\times(\text{host fraction
succumbing parasitism})\\ &amp;\qquad\times(\text{host population
size})
\end{aligned}</me> </p>


<p> Host fecundity is just a constant, <m>\lambda</m>. The host fraction
surviving parasitism is, for now, some arbitrary function of <m>P_t</m>
and <m>H_t</m>, <m>f(H_t, P_t)</m>. The parasitoid production per host
is another constant, <m>c</m>. Since all hosts are either parasitized or
not, the fraction that succumbs to parasitism is <m>1-f(H_t, P_t)</m>.
</p>


<p> The fraction that survives parasitism, <m>f(H_t, P_t)</m>, is an
important component of the model. We will now build a model for this
term using some basic logic, a few key assumptions, and probability. We
define the number of host-parasitoid encounters, <m>E</m>, and assume it
is proportional to the densities of <m>H_t</m> and <m>P_t</m>,
<me>E=aH_tP_t.</me> The parameter <m>a</m> is the constant of
proportionality, and the number of encounters is bilinear in <m>H_t</m>
and <m>P_t</m>. Caterpillars are a fixed size and only ’have space’ for
a fixed number of parasitoids. Think of them as a parasitoid hotel, at
some point all rooms are full and it doesn’t matter how many new
travelers stop - they can try but there are no more rooms left. </p>


<p> On to our last piece of the model: the Poisson distribution. This
distribution governs the number of events to occur in some time
interval, when events occur at some fixed rate, <m>\mu</m>. The
probability of <m>r</m> events is
<me>Q(r)=\frac{e^{-\mu}\mu^r}{r!}.</me> The average number of attacks
per host per generation is
<me>\mu=\frac{E}{H_t}=\frac{aH_tP_t}{H_t}=aP_t.</me> According to our
second assumption we only care whether a host is parasitized or not
(i.e., whether <m>r=0</m> or <m>r&gt;0</m>). Thus, we want <me>f(N_t,
P_t)=Q(0)=\frac{e^{-aP_t}(aP_t)^0}{0!}=e^{-aP_t}.</me> Plugging in
<m>f(H_t, P_t)</m>, <me>\begin{aligned}
 H_{t+1}&amp;= \lambda e^{-a
P_t}H_t\\ P_{t+1}&amp;=c (1-e^{-a P_t})H_t.
\end{aligned}</me> A few
special cases suggest that when <m>P_t=0</m>, <m>H_t</m> grows
geometrically, but when <m>P_t</m> is <sq>large</sq> few hosts escape
parasitism. We might wish to limit host growth in the absence of
parasitism, which could be accomplished by defining
<m>\lambda=\lambda(H_t)</m> as some reasonable decreasing function of
host population density. Some trajectories (for parameters corresponding
to those in the book) are plotted in <xref ref="fig-NB-sols" />.
</p>

<figure xml:id="fig-NB-sols"> 
<image source="./images/pars_pert.png" width="50%"/>
<caption>Sample dynamics of
Nicholson-Bailey. Left) Perturbations in three parameters. Notice that
some host populations appear to escape parasitoids. Right) Perturbations
in initial conditions. Small changes in initial conditions drastically
effect dynamics.</caption> </figure>

<figure xml:id="fig-NB-sols2">
<image source="./images/IC_pert.png" width="50%"/>
<caption>Sample dynamics of
Nicholson-Bailey. Left) Perturbations in three parameters. Notice that
some host populations appear to escape parasitoids. Right) Perturbations
in initial conditions. Small changes in initial conditions drastically
effect dynamics.</caption> </figure>


<p> We can pretty easily see the <sq>problems</sq> with these dynamics.
Actually evaluating the stability conditions for this and other models
is occasionally quite enlightening and can give a nice interpretation of
the relationships between certain terms (rates and interactions) in our
model. One particularly interesting situation occurs when matrix traces
and determinants lie on the edges of stability, where bifurcations are
borne. </p>

</example>

</subsection>

</section>
-->


</chapter>

